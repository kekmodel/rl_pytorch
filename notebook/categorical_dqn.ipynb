{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IWnm3qot3o1W"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import deque\n",
    "from copy import deepcopy\n",
    "\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 708,
     "status": "ok",
     "timestamp": 1534482400648,
     "user": {
      "displayName": "윤승제",
      "photoUrl": "//lh5.googleusercontent.com/-EucKC7DmcQI/AAAAAAAAAAI/AAAAAAAAAGA/gQU1NPEmNFA/s50-c-k-no/photo.jpg",
      "userId": "105654037995838004821"
     },
     "user_tz": -540
    },
    "id": "maRVADiTlzHD",
    "outputId": "783b7610-95c2-4b54-b2ce-d8e853c484ba"
   },
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "BATCH_SIZE = 32\n",
    "LR = 0.00025\n",
    "UP_COEF = 0.01\n",
    "GAMMA = 0.99\n",
    "V_MAX = 10\n",
    "V_MIN = -10\n",
    "N_ATOMS = 51\n",
    "DELTA_Z = (V_MAX - V_MIN) / (N_ATOMS - 1)\n",
    "\n",
    "# set device\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "\n",
    "# random seed\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Ffkl_5C4R81"
   },
   "outputs": [],
   "source": [
    "class CategoricalDQN(nn.Module):\n",
    "    def __init__(self, obs_space, action_space, n_atoms):\n",
    "        super().__init__()\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(obs_space, obs_space*10),\n",
    "            nn.SELU()\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(obs_space*10, 512),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(512, action_space * n_atoms)\n",
    "        )\n",
    "\n",
    "        self.log_softmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "        self.register_buffer(\n",
    "            'support', torch.arange(V_MIN, V_MAX + DELTA_Z, DELTA_Z))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.head(x)\n",
    "        out = self.fc(out).reshape(out.shape[0], -1, N_ATOMS)\n",
    "        log_p = self.log_softmax(out)\n",
    "\n",
    "        return log_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "\n",
    "\n",
    "def learn(net, tgt_net, optimizer, rep_memory):\n",
    "    net.train()\n",
    "    tgt_net.train()\n",
    "    \n",
    "    train_memory = random.sample(rep_memory, BATCH_SIZE)\n",
    "\n",
    "    dataloader = DataLoader(train_memory,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            pin_memory=use_cuda)\n",
    "\n",
    "    for i, (s, a, r, _s, d) in enumerate(dataloader):\n",
    "        s = s.to(device).float()\n",
    "        a = a.to(device).long()\n",
    "        _s = _s.to(device).float()\n",
    "        r = r.to(device).float()\n",
    "        d = d.to(device).float()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            _log_p = net(_s)\n",
    "            _weight = _log_p.exp() * net.support\n",
    "            _q = _weight.sum(dim=2)\n",
    "            _a = torch.argmax(_q, dim=1)\n",
    "            _log_p_tgt = tgt_net(_s)\n",
    "            _log_p_a = _log_p_tgt[range(BATCH_SIZE), _a]\n",
    "            _p_a = _log_p_a.exp()\n",
    "            _p_proj = projection(_p_a, r, d)\n",
    "        \n",
    "        log_p = net(s)\n",
    "        log_p_a = log_p[range(BATCH_SIZE), a]\n",
    "\n",
    "        # loss\n",
    "        loss = -(_p_proj * log_p_a).sum(dim=1).mean()\n",
    "        losses.append(loss)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def projection(_p_a, r, d):\n",
    "    _p_proj = np.zeros((BATCH_SIZE, N_ATOMS), dtype=np.float32)\n",
    "    r_np = r.cpu().numpy()\n",
    "    d_np = d.cpu().numpy()\n",
    "    _p_a_np = _p_a.cpu().numpy()\n",
    "    batch_id = range(BATCH_SIZE)\n",
    "    for i in range(N_ATOMS):\n",
    "        z = np.clip(r_np + GAMMA * (1 - d_np) * (V_MIN + i * DELTA_Z),\n",
    "                    V_MIN, V_MAX)\n",
    "        b = (z - V_MIN) / DELTA_Z\n",
    "        l = np.floor(b).astype(np.int64)\n",
    "        u = np.ceil(b).astype(np.int64)\n",
    "        _p_proj[batch_id, l[batch_id]] += d_np + _p_a_np[batch_id, i] * (u - b)[batch_id] * (1 - d_np)\n",
    "        _p_proj[batch_id, u[batch_id]] += d_np + _p_a_np[batch_id, i] * (b - l)[batch_id] * (1 - d_np)\n",
    "        \n",
    "    _p_proj = _p_proj / _p_proj.sum(axis=1, keepdims=1)\n",
    "    \n",
    "    return torch.tensor(_p_proj).to(device).float()\n",
    "\n",
    "\n",
    "def select_action(obs, tgt_net):\n",
    "    tgt_net.eval()\n",
    "    with torch.no_grad():\n",
    "        state = torch.tensor([obs]).to(device).float()\n",
    "        log_p = target_net(state)\n",
    "        weights = log_p.exp() * net.support\n",
    "        q = weights.sum(dim=2)\n",
    "        action = torch.argmax(q, dim=1)\n",
    "\n",
    "    return action.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3377
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 135196,
     "status": "ok",
     "timestamp": 1534482559393,
     "user": {
      "displayName": "윤승제",
      "photoUrl": "//lh5.googleusercontent.com/-EucKC7DmcQI/AAAAAAAAAAI/AAAAAAAAAGA/gQU1NPEmNFA/s50-c-k-no/photo.jpg",
      "userId": "105654037995838004821"
     },
     "user_tz": -540
    },
    "id": "PnifSBJglzHh",
    "outputId": "94177345-918e-4a96-d9a8-d8aba0a4bc9a",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jay/anaconda3/lib/python3.6/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    }
   ],
   "source": [
    "# make an environment\n",
    "# env = gym.make('CartPole-v0')\n",
    "env = gym.make('CartPole-v1')\n",
    "# env = gym.make('MountainCar-v0')\n",
    "# env = gym.make('LunarLander-v2')\n",
    "\n",
    "env.seed(SEED)\n",
    "obs_space = env.observation_space.shape[0]\n",
    "action_space = env.action_space.n\n",
    "\n",
    "# hyperparameter\n",
    "n_episodes = 1000\n",
    "learn_start = 1500\n",
    "memory_size = 100000\n",
    "update_frq = 1\n",
    "use_eps_decay = False\n",
    "epsilon = 0.001\n",
    "eps_min = 0.001\n",
    "decay_rate = 0.0001\n",
    "n_eval = env.spec.trials\n",
    "\n",
    "# global values\n",
    "total_steps = 0\n",
    "learn_steps = 0\n",
    "rewards = []\n",
    "reward_eval = deque(maxlen=n_eval)\n",
    "is_learned = False\n",
    "is_solved = False\n",
    "\n",
    "# make a memory\n",
    "rep_memory = deque(maxlen=memory_size)\n",
    "\n",
    "# make two nerual networks\n",
    "net = CategoricalDQN(obs_space, action_space, N_ATOMS).to(device)\n",
    "target_net = deepcopy(net)\n",
    "\n",
    "# make a optimizer\n",
    "optimizer = optim.Adam(net.parameters(), lr=LR, eps=1e-5)\n",
    "# optimizer = optim.SGD(net.parameters(), lr=LR, momentum=0.9, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.spec.max_episode_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.spec.trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "475.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.spec.reward_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3377
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 135196,
     "status": "ok",
     "timestamp": 1534482559393,
     "user": {
      "displayName": "윤승제",
      "photoUrl": "//lh5.googleusercontent.com/-EucKC7DmcQI/AAAAAAAAAAI/AAAAAAAAAGA/gQU1NPEmNFA/s50-c-k-no/photo.jpg",
      "userId": "105654037995838004821"
     },
     "user_tz": -540
    },
    "id": "PnifSBJglzHh",
    "outputId": "94177345-918e-4a96-d9a8-d8aba0a4bc9a",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1 Episode in    10 steps, reward 10.00\n",
      "  2 Episode in    20 steps, reward 10.00\n",
      "  3 Episode in    28 steps, reward 8.00\n",
      "  4 Episode in    36 steps, reward 8.00\n",
      "  5 Episode in    44 steps, reward 8.00\n",
      "  6 Episode in    53 steps, reward 9.00\n",
      "  7 Episode in    63 steps, reward 10.00\n",
      "  8 Episode in    71 steps, reward 8.00\n",
      "  9 Episode in    80 steps, reward 9.00\n",
      " 10 Episode in    89 steps, reward 9.00\n",
      " 11 Episode in    99 steps, reward 10.00\n",
      " 12 Episode in   109 steps, reward 10.00\n",
      " 13 Episode in   119 steps, reward 10.00\n",
      " 14 Episode in   129 steps, reward 10.00\n",
      " 15 Episode in   138 steps, reward 9.00\n",
      " 16 Episode in   146 steps, reward 8.00\n",
      " 17 Episode in   155 steps, reward 9.00\n",
      " 18 Episode in   165 steps, reward 10.00\n",
      " 19 Episode in   175 steps, reward 10.00\n",
      " 20 Episode in   185 steps, reward 10.00\n",
      " 21 Episode in   195 steps, reward 10.00\n",
      " 22 Episode in   205 steps, reward 10.00\n",
      " 23 Episode in   215 steps, reward 10.00\n",
      " 24 Episode in   223 steps, reward 8.00\n",
      " 25 Episode in   231 steps, reward 8.00\n",
      " 26 Episode in   240 steps, reward 9.00\n",
      " 27 Episode in   250 steps, reward 10.00\n",
      " 28 Episode in   262 steps, reward 12.00\n",
      " 29 Episode in   271 steps, reward 9.00\n",
      " 30 Episode in   281 steps, reward 10.00\n",
      " 31 Episode in   291 steps, reward 10.00\n",
      " 32 Episode in   300 steps, reward 9.00\n",
      " 33 Episode in   310 steps, reward 10.00\n",
      " 34 Episode in   320 steps, reward 10.00\n",
      " 35 Episode in   330 steps, reward 10.00\n",
      " 36 Episode in   340 steps, reward 10.00\n",
      " 37 Episode in   350 steps, reward 10.00\n",
      " 38 Episode in   359 steps, reward 9.00\n",
      " 39 Episode in   368 steps, reward 9.00\n",
      " 40 Episode in   376 steps, reward 8.00\n",
      " 41 Episode in   386 steps, reward 10.00\n",
      " 42 Episode in   394 steps, reward 8.00\n",
      " 43 Episode in   403 steps, reward 9.00\n",
      " 44 Episode in   412 steps, reward 9.00\n",
      " 45 Episode in   422 steps, reward 10.00\n",
      " 46 Episode in   432 steps, reward 10.00\n",
      " 47 Episode in   441 steps, reward 9.00\n",
      " 48 Episode in   451 steps, reward 10.00\n",
      " 49 Episode in   461 steps, reward 10.00\n",
      " 50 Episode in   469 steps, reward 8.00\n",
      " 51 Episode in   478 steps, reward 9.00\n",
      " 52 Episode in   487 steps, reward 9.00\n",
      " 53 Episode in   496 steps, reward 9.00\n",
      " 54 Episode in   506 steps, reward 10.00\n",
      " 55 Episode in   516 steps, reward 10.00\n",
      " 56 Episode in   526 steps, reward 10.00\n",
      " 57 Episode in   535 steps, reward 9.00\n",
      " 58 Episode in   543 steps, reward 8.00\n",
      " 59 Episode in   554 steps, reward 11.00\n",
      " 60 Episode in   562 steps, reward 8.00\n",
      " 61 Episode in   572 steps, reward 10.00\n",
      " 62 Episode in   581 steps, reward 9.00\n",
      " 63 Episode in   591 steps, reward 10.00\n",
      " 64 Episode in   600 steps, reward 9.00\n",
      " 65 Episode in   609 steps, reward 9.00\n",
      " 66 Episode in   618 steps, reward 9.00\n",
      " 67 Episode in   627 steps, reward 9.00\n",
      " 68 Episode in   636 steps, reward 9.00\n",
      " 69 Episode in   646 steps, reward 10.00\n",
      " 70 Episode in   654 steps, reward 8.00\n",
      " 71 Episode in   662 steps, reward 8.00\n",
      " 72 Episode in   672 steps, reward 10.00\n",
      " 73 Episode in   681 steps, reward 9.00\n",
      " 74 Episode in   691 steps, reward 10.00\n",
      " 75 Episode in   701 steps, reward 10.00\n",
      " 76 Episode in   711 steps, reward 10.00\n",
      " 77 Episode in   721 steps, reward 10.00\n",
      " 78 Episode in   731 steps, reward 10.00\n",
      " 79 Episode in   739 steps, reward 8.00\n",
      " 80 Episode in   747 steps, reward 8.00\n",
      " 81 Episode in   757 steps, reward 10.00\n",
      " 82 Episode in   766 steps, reward 9.00\n",
      " 83 Episode in   776 steps, reward 10.00\n",
      " 84 Episode in   785 steps, reward 9.00\n",
      " 85 Episode in   795 steps, reward 10.00\n",
      " 86 Episode in   805 steps, reward 10.00\n",
      " 87 Episode in   814 steps, reward 9.00\n",
      " 88 Episode in   824 steps, reward 10.00\n",
      " 89 Episode in   834 steps, reward 10.00\n",
      " 90 Episode in   844 steps, reward 10.00\n",
      " 91 Episode in   854 steps, reward 10.00\n",
      " 92 Episode in   864 steps, reward 10.00\n",
      " 93 Episode in   874 steps, reward 10.00\n",
      " 94 Episode in   883 steps, reward 9.00\n",
      " 95 Episode in   892 steps, reward 9.00\n",
      " 96 Episode in   902 steps, reward 10.00\n",
      " 97 Episode in   911 steps, reward 9.00\n",
      " 98 Episode in   920 steps, reward 9.00\n",
      " 99 Episode in   929 steps, reward 9.00\n",
      "100 Episode in   939 steps, reward 10.00\n",
      "101 Episode in   948 steps, reward 9.00\n",
      "102 Episode in   958 steps, reward 10.00\n",
      "103 Episode in   967 steps, reward 9.00\n",
      "104 Episode in   976 steps, reward 9.00\n",
      "105 Episode in   985 steps, reward 9.00\n",
      "106 Episode in   994 steps, reward 9.00\n",
      "107 Episode in  1003 steps, reward 9.00\n",
      "108 Episode in  1013 steps, reward 10.00\n",
      "109 Episode in  1022 steps, reward 9.00\n",
      "110 Episode in  1032 steps, reward 10.00\n",
      "111 Episode in  1041 steps, reward 9.00\n",
      "112 Episode in  1050 steps, reward 9.00\n",
      "113 Episode in  1059 steps, reward 9.00\n",
      "114 Episode in  1068 steps, reward 9.00\n",
      "115 Episode in  1077 steps, reward 9.00\n",
      "116 Episode in  1088 steps, reward 11.00\n",
      "117 Episode in  1097 steps, reward 9.00\n",
      "118 Episode in  1107 steps, reward 10.00\n",
      "119 Episode in  1116 steps, reward 9.00\n",
      "120 Episode in  1126 steps, reward 10.00\n",
      "121 Episode in  1134 steps, reward 8.00\n",
      "122 Episode in  1143 steps, reward 9.00\n",
      "123 Episode in  1153 steps, reward 10.00\n",
      "124 Episode in  1163 steps, reward 10.00\n",
      "125 Episode in  1172 steps, reward 9.00\n",
      "126 Episode in  1182 steps, reward 10.00\n",
      "127 Episode in  1192 steps, reward 10.00\n",
      "128 Episode in  1200 steps, reward 8.00\n",
      "129 Episode in  1208 steps, reward 8.00\n",
      "130 Episode in  1218 steps, reward 10.00\n",
      "131 Episode in  1227 steps, reward 9.00\n",
      "132 Episode in  1237 steps, reward 10.00\n",
      "133 Episode in  1248 steps, reward 11.00\n",
      "134 Episode in  1256 steps, reward 8.00\n",
      "135 Episode in  1265 steps, reward 9.00\n",
      "136 Episode in  1273 steps, reward 8.00\n",
      "137 Episode in  1282 steps, reward 9.00\n",
      "138 Episode in  1291 steps, reward 9.00\n",
      "139 Episode in  1302 steps, reward 11.00\n",
      "140 Episode in  1312 steps, reward 10.00\n",
      "141 Episode in  1322 steps, reward 10.00\n",
      "142 Episode in  1332 steps, reward 10.00\n",
      "143 Episode in  1341 steps, reward 9.00\n",
      "144 Episode in  1349 steps, reward 8.00\n",
      "145 Episode in  1359 steps, reward 10.00\n",
      "146 Episode in  1369 steps, reward 10.00\n",
      "147 Episode in  1379 steps, reward 10.00\n",
      "148 Episode in  1387 steps, reward 8.00\n",
      "149 Episode in  1397 steps, reward 10.00\n",
      "150 Episode in  1405 steps, reward 8.00\n",
      "151 Episode in  1414 steps, reward 9.00\n",
      "152 Episode in  1424 steps, reward 10.00\n",
      "153 Episode in  1434 steps, reward 10.00\n",
      "154 Episode in  1444 steps, reward 10.00\n",
      "155 Episode in  1453 steps, reward 9.00\n",
      "156 Episode in  1463 steps, reward 10.00\n",
      "157 Episode in  1474 steps, reward 11.00\n",
      "158 Episode in  1482 steps, reward 8.00\n",
      "159 Episode in  1491 steps, reward 9.00\n",
      "\n",
      "============  Start Learning  ============\n",
      "\n",
      "160 Episode in  1501 steps, reward 10.00\n",
      "161 Episode in  1510 steps, reward 9.00\n",
      "162 Episode in  1520 steps, reward 10.00\n",
      "163 Episode in  1529 steps, reward 9.00\n",
      "164 Episode in  1538 steps, reward 9.00\n",
      "165 Episode in  1548 steps, reward 10.00\n",
      "166 Episode in  1557 steps, reward 9.00\n",
      "167 Episode in  1566 steps, reward 9.00\n",
      "168 Episode in  1575 steps, reward 9.00\n",
      "169 Episode in  1584 steps, reward 9.00\n",
      "170 Episode in  1594 steps, reward 10.00\n",
      "171 Episode in  1603 steps, reward 9.00\n",
      "172 Episode in  1612 steps, reward 9.00\n",
      "173 Episode in  1623 steps, reward 11.00\n",
      "174 Episode in  1633 steps, reward 10.00\n",
      "175 Episode in  1643 steps, reward 10.00\n",
      "176 Episode in  1652 steps, reward 9.00\n",
      "177 Episode in  1662 steps, reward 10.00\n",
      "178 Episode in  1670 steps, reward 8.00\n",
      "179 Episode in  1679 steps, reward 9.00\n",
      "180 Episode in  1688 steps, reward 9.00\n",
      "181 Episode in  1698 steps, reward 10.00\n",
      "182 Episode in  1708 steps, reward 10.00\n",
      "183 Episode in  1717 steps, reward 9.00\n",
      "184 Episode in  1727 steps, reward 10.00\n",
      "185 Episode in  1737 steps, reward 10.00\n",
      "186 Episode in  1746 steps, reward 9.00\n",
      "187 Episode in  1756 steps, reward 10.00\n",
      "188 Episode in  1765 steps, reward 9.00\n",
      "189 Episode in  1774 steps, reward 9.00\n",
      "190 Episode in  1782 steps, reward 8.00\n",
      "191 Episode in  1793 steps, reward 11.00\n",
      "192 Episode in  1803 steps, reward 10.00\n",
      "193 Episode in  1812 steps, reward 9.00\n",
      "194 Episode in  1820 steps, reward 8.00\n",
      "195 Episode in  1830 steps, reward 10.00\n",
      "196 Episode in  1839 steps, reward 9.00\n",
      "197 Episode in  1849 steps, reward 10.00\n",
      "198 Episode in  1859 steps, reward 10.00\n",
      "199 Episode in  1869 steps, reward 10.00\n",
      "200 Episode in  1878 steps, reward 9.00\n",
      "201 Episode in  1887 steps, reward 9.00\n",
      "202 Episode in  1897 steps, reward 10.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203 Episode in  1907 steps, reward 10.00\n",
      "204 Episode in  1918 steps, reward 11.00\n",
      "205 Episode in  1927 steps, reward 9.00\n",
      "206 Episode in  1937 steps, reward 10.00\n",
      "207 Episode in  1947 steps, reward 10.00\n",
      "208 Episode in  1955 steps, reward 8.00\n",
      "209 Episode in  1965 steps, reward 10.00\n",
      "210 Episode in  1975 steps, reward 10.00\n",
      "211 Episode in  1984 steps, reward 9.00\n",
      "212 Episode in  1995 steps, reward 11.00\n",
      "213 Episode in  2003 steps, reward 8.00\n",
      "214 Episode in  2013 steps, reward 10.00\n",
      "215 Episode in  2023 steps, reward 10.00\n",
      "216 Episode in  2032 steps, reward 9.00\n",
      "217 Episode in  2041 steps, reward 9.00\n",
      "218 Episode in  2051 steps, reward 10.00\n",
      "219 Episode in  2061 steps, reward 10.00\n",
      "220 Episode in  2070 steps, reward 9.00\n",
      "221 Episode in  2081 steps, reward 11.00\n",
      "222 Episode in  2091 steps, reward 10.00\n",
      "223 Episode in  2101 steps, reward 10.00\n",
      "224 Episode in  2109 steps, reward 8.00\n",
      "225 Episode in  2117 steps, reward 8.00\n",
      "226 Episode in  2126 steps, reward 9.00\n",
      "227 Episode in  2135 steps, reward 9.00\n",
      "228 Episode in  2145 steps, reward 10.00\n",
      "229 Episode in  2154 steps, reward 9.00\n",
      "230 Episode in  2164 steps, reward 10.00\n",
      "231 Episode in  2174 steps, reward 10.00\n",
      "232 Episode in  2184 steps, reward 10.00\n",
      "233 Episode in  2194 steps, reward 10.00\n",
      "234 Episode in  2204 steps, reward 10.00\n",
      "235 Episode in  2214 steps, reward 10.00\n",
      "236 Episode in  2223 steps, reward 9.00\n",
      "237 Episode in  2232 steps, reward 9.00\n",
      "238 Episode in  2242 steps, reward 10.00\n",
      "239 Episode in  2251 steps, reward 9.00\n",
      "240 Episode in  2260 steps, reward 9.00\n",
      "241 Episode in  2269 steps, reward 9.00\n",
      "242 Episode in  2278 steps, reward 9.00\n",
      "243 Episode in  2288 steps, reward 10.00\n",
      "244 Episode in  2297 steps, reward 9.00\n",
      "245 Episode in  2306 steps, reward 9.00\n",
      "246 Episode in  2316 steps, reward 10.00\n",
      "247 Episode in  2326 steps, reward 10.00\n",
      "248 Episode in  2335 steps, reward 9.00\n",
      "249 Episode in  2344 steps, reward 9.00\n",
      "250 Episode in  2354 steps, reward 10.00\n",
      "251 Episode in  2385 steps, reward 31.00\n",
      "252 Episode in  2425 steps, reward 40.00\n",
      "253 Episode in  2460 steps, reward 35.00\n",
      "254 Episode in  2492 steps, reward 32.00\n",
      "255 Episode in  2520 steps, reward 28.00\n",
      "256 Episode in  2552 steps, reward 32.00\n",
      "257 Episode in  2576 steps, reward 24.00\n",
      "258 Episode in  2595 steps, reward 19.00\n",
      "259 Episode in  2611 steps, reward 16.00\n",
      "260 Episode in  2626 steps, reward 15.00\n",
      "261 Episode in  2641 steps, reward 15.00\n",
      "262 Episode in  2656 steps, reward 15.00\n",
      "263 Episode in  2673 steps, reward 17.00\n",
      "264 Episode in  2688 steps, reward 15.00\n",
      "265 Episode in  2700 steps, reward 12.00\n",
      "266 Episode in  2711 steps, reward 11.00\n",
      "267 Episode in  2723 steps, reward 12.00\n",
      "268 Episode in  2734 steps, reward 11.00\n",
      "269 Episode in  2745 steps, reward 11.00\n",
      "270 Episode in  2757 steps, reward 12.00\n",
      "271 Episode in  2768 steps, reward 11.00\n",
      "272 Episode in  2778 steps, reward 10.00\n",
      "273 Episode in  2787 steps, reward 9.00\n",
      "274 Episode in  2797 steps, reward 10.00\n",
      "275 Episode in  2806 steps, reward 9.00\n",
      "276 Episode in  2815 steps, reward 9.00\n",
      "277 Episode in  2824 steps, reward 9.00\n",
      "278 Episode in  2833 steps, reward 9.00\n",
      "279 Episode in  2841 steps, reward 8.00\n",
      "280 Episode in  2850 steps, reward 9.00\n",
      "281 Episode in  2859 steps, reward 9.00\n",
      "282 Episode in  2868 steps, reward 9.00\n",
      "283 Episode in  2878 steps, reward 10.00\n",
      "284 Episode in  2888 steps, reward 10.00\n",
      "285 Episode in  2897 steps, reward 9.00\n",
      "286 Episode in  2906 steps, reward 9.00\n",
      "287 Episode in  2916 steps, reward 10.00\n",
      "288 Episode in  2924 steps, reward 8.00\n",
      "289 Episode in  2932 steps, reward 8.00\n",
      "290 Episode in  2941 steps, reward 9.00\n",
      "291 Episode in  2950 steps, reward 9.00\n",
      "292 Episode in  2960 steps, reward 10.00\n",
      "293 Episode in  2969 steps, reward 9.00\n",
      "294 Episode in  2978 steps, reward 9.00\n",
      "295 Episode in  2988 steps, reward 10.00\n",
      "296 Episode in  2999 steps, reward 11.00\n",
      "297 Episode in  3007 steps, reward 8.00\n",
      "298 Episode in  3016 steps, reward 9.00\n",
      "299 Episode in  3024 steps, reward 8.00\n",
      "300 Episode in  3034 steps, reward 10.00\n",
      "301 Episode in  3044 steps, reward 10.00\n",
      "302 Episode in  3053 steps, reward 9.00\n",
      "303 Episode in  3062 steps, reward 9.00\n",
      "304 Episode in  3075 steps, reward 13.00\n",
      "305 Episode in  3086 steps, reward 11.00\n",
      "306 Episode in  3098 steps, reward 12.00\n",
      "307 Episode in  3110 steps, reward 12.00\n",
      "308 Episode in  3125 steps, reward 15.00\n",
      "309 Episode in  3144 steps, reward 19.00\n",
      "310 Episode in  3161 steps, reward 17.00\n",
      "311 Episode in  3173 steps, reward 12.00\n",
      "312 Episode in  3186 steps, reward 13.00\n",
      "313 Episode in  3202 steps, reward 16.00\n",
      "314 Episode in  3219 steps, reward 17.00\n",
      "315 Episode in  3238 steps, reward 19.00\n",
      "316 Episode in  3258 steps, reward 20.00\n",
      "317 Episode in  3276 steps, reward 18.00\n",
      "318 Episode in  3296 steps, reward 20.00\n",
      "319 Episode in  3312 steps, reward 16.00\n",
      "320 Episode in  3341 steps, reward 29.00\n",
      "321 Episode in  3367 steps, reward 26.00\n",
      "322 Episode in  3391 steps, reward 24.00\n",
      "323 Episode in  3415 steps, reward 24.00\n",
      "324 Episode in  3462 steps, reward 47.00\n",
      "325 Episode in  3527 steps, reward 65.00\n",
      "326 Episode in  3561 steps, reward 34.00\n",
      "327 Episode in  3610 steps, reward 49.00\n",
      "328 Episode in  3653 steps, reward 43.00\n",
      "329 Episode in  3697 steps, reward 44.00\n",
      "330 Episode in  3836 steps, reward 139.00\n",
      "331 Episode in  4010 steps, reward 174.00\n",
      "332 Episode in  4196 steps, reward 186.00\n",
      "333 Episode in  4379 steps, reward 183.00\n",
      "334 Episode in  4567 steps, reward 188.00\n",
      "335 Episode in  4736 steps, reward 169.00\n",
      "336 Episode in  4921 steps, reward 185.00\n",
      "337 Episode in  5108 steps, reward 187.00\n",
      "338 Episode in  5288 steps, reward 180.00\n",
      "339 Episode in  5477 steps, reward 189.00\n",
      "340 Episode in  5658 steps, reward 181.00\n",
      "341 Episode in  5828 steps, reward 170.00\n",
      "342 Episode in  5996 steps, reward 168.00\n",
      "343 Episode in  6159 steps, reward 163.00\n",
      "344 Episode in  6320 steps, reward 161.00\n",
      "345 Episode in  6488 steps, reward 168.00\n",
      "346 Episode in  6652 steps, reward 164.00\n",
      "347 Episode in  6813 steps, reward 161.00\n",
      "348 Episode in  6982 steps, reward 169.00\n",
      "349 Episode in  7157 steps, reward 175.00\n",
      "350 Episode in  7333 steps, reward 176.00\n",
      "351 Episode in  7487 steps, reward 154.00\n",
      "352 Episode in  7659 steps, reward 172.00\n",
      "353 Episode in  7812 steps, reward 153.00\n",
      "354 Episode in  7983 steps, reward 171.00\n",
      "355 Episode in  8147 steps, reward 164.00\n",
      "356 Episode in  8313 steps, reward 166.00\n",
      "357 Episode in  8463 steps, reward 150.00\n",
      "358 Episode in  8617 steps, reward 154.00\n",
      "359 Episode in  8777 steps, reward 160.00\n",
      "360 Episode in  8939 steps, reward 162.00\n",
      "361 Episode in  9093 steps, reward 154.00\n",
      "362 Episode in  9243 steps, reward 150.00\n",
      "363 Episode in  9408 steps, reward 165.00\n",
      "364 Episode in  9568 steps, reward 160.00\n",
      "365 Episode in  9718 steps, reward 150.00\n",
      "366 Episode in  9879 steps, reward 161.00\n",
      "367 Episode in 10034 steps, reward 155.00\n",
      "368 Episode in 10189 steps, reward 155.00\n",
      "369 Episode in 10343 steps, reward 154.00\n",
      "370 Episode in 10507 steps, reward 164.00\n",
      "371 Episode in 10659 steps, reward 152.00\n",
      "372 Episode in 10805 steps, reward 146.00\n",
      "373 Episode in 10959 steps, reward 154.00\n",
      "374 Episode in 11127 steps, reward 168.00\n",
      "375 Episode in 11284 steps, reward 157.00\n",
      "376 Episode in 11432 steps, reward 148.00\n",
      "377 Episode in 11585 steps, reward 153.00\n",
      "378 Episode in 11736 steps, reward 151.00\n",
      "379 Episode in 11891 steps, reward 155.00\n",
      "380 Episode in 12045 steps, reward 154.00\n",
      "381 Episode in 12205 steps, reward 160.00\n",
      "382 Episode in 12355 steps, reward 150.00\n",
      "383 Episode in 12513 steps, reward 158.00\n",
      "384 Episode in 12663 steps, reward 150.00\n",
      "385 Episode in 12819 steps, reward 156.00\n",
      "386 Episode in 12967 steps, reward 148.00\n",
      "387 Episode in 13113 steps, reward 146.00\n",
      "388 Episode in 13263 steps, reward 150.00\n",
      "389 Episode in 13415 steps, reward 152.00\n",
      "390 Episode in 13559 steps, reward 144.00\n",
      "391 Episode in 13716 steps, reward 157.00\n",
      "392 Episode in 13868 steps, reward 152.00\n",
      "393 Episode in 14013 steps, reward 145.00\n",
      "394 Episode in 14160 steps, reward 147.00\n",
      "395 Episode in 14300 steps, reward 140.00\n",
      "396 Episode in 14453 steps, reward 153.00\n",
      "397 Episode in 14604 steps, reward 151.00\n",
      "398 Episode in 14752 steps, reward 148.00\n",
      "399 Episode in 14898 steps, reward 146.00\n",
      "400 Episode in 15038 steps, reward 140.00\n",
      "401 Episode in 15187 steps, reward 149.00\n",
      "402 Episode in 15331 steps, reward 144.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403 Episode in 15479 steps, reward 148.00\n",
      "404 Episode in 15631 steps, reward 152.00\n",
      "405 Episode in 15771 steps, reward 140.00\n",
      "406 Episode in 15919 steps, reward 148.00\n",
      "407 Episode in 16068 steps, reward 149.00\n",
      "408 Episode in 16214 steps, reward 146.00\n",
      "409 Episode in 16361 steps, reward 147.00\n",
      "410 Episode in 16509 steps, reward 148.00\n",
      "411 Episode in 16661 steps, reward 152.00\n",
      "412 Episode in 16811 steps, reward 150.00\n",
      "413 Episode in 16952 steps, reward 141.00\n",
      "414 Episode in 17101 steps, reward 149.00\n",
      "415 Episode in 17241 steps, reward 140.00\n",
      "416 Episode in 17393 steps, reward 152.00\n",
      "417 Episode in 17534 steps, reward 141.00\n",
      "418 Episode in 17678 steps, reward 144.00\n",
      "419 Episode in 17825 steps, reward 147.00\n",
      "420 Episode in 17961 steps, reward 136.00\n",
      "421 Episode in 18101 steps, reward 140.00\n",
      "422 Episode in 18246 steps, reward 145.00\n",
      "423 Episode in 18399 steps, reward 153.00\n",
      "424 Episode in 18547 steps, reward 148.00\n",
      "425 Episode in 18688 steps, reward 141.00\n",
      "426 Episode in 18835 steps, reward 147.00\n",
      "427 Episode in 18977 steps, reward 142.00\n",
      "428 Episode in 19117 steps, reward 140.00\n",
      "429 Episode in 19260 steps, reward 143.00\n",
      "430 Episode in 19407 steps, reward 147.00\n",
      "431 Episode in 19545 steps, reward 138.00\n",
      "432 Episode in 19687 steps, reward 142.00\n",
      "433 Episode in 19836 steps, reward 149.00\n",
      "434 Episode in 19996 steps, reward 160.00\n",
      "435 Episode in 20144 steps, reward 148.00\n",
      "436 Episode in 20296 steps, reward 152.00\n",
      "437 Episode in 20443 steps, reward 147.00\n",
      "438 Episode in 20584 steps, reward 141.00\n",
      "439 Episode in 20731 steps, reward 147.00\n",
      "440 Episode in 20874 steps, reward 143.00\n",
      "441 Episode in 21016 steps, reward 142.00\n",
      "442 Episode in 21157 steps, reward 141.00\n",
      "443 Episode in 21299 steps, reward 142.00\n",
      "444 Episode in 21454 steps, reward 155.00\n",
      "445 Episode in 21586 steps, reward 132.00\n",
      "446 Episode in 21725 steps, reward 139.00\n",
      "447 Episode in 21864 steps, reward 139.00\n",
      "448 Episode in 21998 steps, reward 134.00\n",
      "449 Episode in 22135 steps, reward 137.00\n",
      "450 Episode in 22278 steps, reward 143.00\n",
      "451 Episode in 22419 steps, reward 141.00\n",
      "452 Episode in 22566 steps, reward 147.00\n",
      "453 Episode in 22706 steps, reward 140.00\n",
      "454 Episode in 22843 steps, reward 137.00\n",
      "455 Episode in 22987 steps, reward 144.00\n",
      "456 Episode in 23131 steps, reward 144.00\n",
      "457 Episode in 23275 steps, reward 144.00\n",
      "458 Episode in 23419 steps, reward 144.00\n",
      "459 Episode in 23568 steps, reward 149.00\n",
      "460 Episode in 23711 steps, reward 143.00\n",
      "461 Episode in 23855 steps, reward 144.00\n",
      "462 Episode in 23998 steps, reward 143.00\n",
      "463 Episode in 24147 steps, reward 149.00\n",
      "464 Episode in 24297 steps, reward 150.00\n",
      "465 Episode in 24459 steps, reward 162.00\n",
      "466 Episode in 24606 steps, reward 147.00\n",
      "467 Episode in 24751 steps, reward 145.00\n",
      "468 Episode in 24902 steps, reward 151.00\n",
      "469 Episode in 25049 steps, reward 147.00\n",
      "470 Episode in 25192 steps, reward 143.00\n",
      "471 Episode in 25338 steps, reward 146.00\n",
      "472 Episode in 25488 steps, reward 150.00\n",
      "473 Episode in 25629 steps, reward 141.00\n",
      "474 Episode in 25771 steps, reward 142.00\n",
      "475 Episode in 25924 steps, reward 153.00\n",
      "476 Episode in 26073 steps, reward 149.00\n",
      "477 Episode in 26213 steps, reward 140.00\n",
      "478 Episode in 26369 steps, reward 156.00\n",
      "479 Episode in 26510 steps, reward 141.00\n",
      "480 Episode in 26654 steps, reward 144.00\n",
      "481 Episode in 26818 steps, reward 164.00\n",
      "482 Episode in 27050 steps, reward 232.00\n",
      "483 Episode in 27235 steps, reward 185.00\n",
      "484 Episode in 27411 steps, reward 176.00\n",
      "485 Episode in 27592 steps, reward 181.00\n",
      "486 Episode in 27768 steps, reward 176.00\n",
      "487 Episode in 27916 steps, reward 148.00\n",
      "488 Episode in 28060 steps, reward 144.00\n",
      "489 Episode in 28212 steps, reward 152.00\n",
      "490 Episode in 28373 steps, reward 161.00\n",
      "491 Episode in 28542 steps, reward 169.00\n",
      "492 Episode in 28728 steps, reward 186.00\n",
      "493 Episode in 28892 steps, reward 164.00\n",
      "494 Episode in 29038 steps, reward 146.00\n",
      "495 Episode in 29192 steps, reward 154.00\n",
      "496 Episode in 29337 steps, reward 145.00\n",
      "497 Episode in 29481 steps, reward 144.00\n",
      "498 Episode in 29634 steps, reward 153.00\n",
      "499 Episode in 29801 steps, reward 167.00\n",
      "500 Episode in 29957 steps, reward 156.00\n",
      "501 Episode in 30136 steps, reward 179.00\n",
      "502 Episode in 30301 steps, reward 165.00\n",
      "503 Episode in 30482 steps, reward 181.00\n",
      "504 Episode in 30679 steps, reward 197.00\n",
      "505 Episode in 30842 steps, reward 163.00\n",
      "506 Episode in 30996 steps, reward 154.00\n",
      "507 Episode in 31139 steps, reward 143.00\n",
      "508 Episode in 31287 steps, reward 148.00\n",
      "509 Episode in 31447 steps, reward 160.00\n",
      "510 Episode in 31618 steps, reward 171.00\n",
      "511 Episode in 31767 steps, reward 149.00\n",
      "512 Episode in 31917 steps, reward 150.00\n",
      "513 Episode in 32072 steps, reward 155.00\n",
      "514 Episode in 32265 steps, reward 193.00\n",
      "515 Episode in 32428 steps, reward 163.00\n",
      "516 Episode in 32569 steps, reward 141.00\n",
      "517 Episode in 32710 steps, reward 141.00\n",
      "518 Episode in 32847 steps, reward 137.00\n",
      "519 Episode in 33005 steps, reward 158.00\n",
      "520 Episode in 33153 steps, reward 148.00\n",
      "521 Episode in 33296 steps, reward 143.00\n",
      "522 Episode in 33451 steps, reward 155.00\n",
      "523 Episode in 33598 steps, reward 147.00\n",
      "524 Episode in 33776 steps, reward 178.00\n",
      "525 Episode in 33945 steps, reward 169.00\n",
      "526 Episode in 34099 steps, reward 154.00\n",
      "527 Episode in 34268 steps, reward 169.00\n",
      "528 Episode in 34421 steps, reward 153.00\n",
      "529 Episode in 34564 steps, reward 143.00\n",
      "530 Episode in 34705 steps, reward 141.00\n",
      "531 Episode in 34847 steps, reward 142.00\n",
      "532 Episode in 34989 steps, reward 142.00\n",
      "533 Episode in 35122 steps, reward 133.00\n",
      "534 Episode in 35271 steps, reward 149.00\n",
      "535 Episode in 35413 steps, reward 142.00\n",
      "536 Episode in 35561 steps, reward 148.00\n",
      "537 Episode in 35701 steps, reward 140.00\n",
      "538 Episode in 35849 steps, reward 148.00\n",
      "539 Episode in 35996 steps, reward 147.00\n",
      "540 Episode in 36152 steps, reward 156.00\n",
      "541 Episode in 36291 steps, reward 139.00\n",
      "542 Episode in 36436 steps, reward 145.00\n",
      "543 Episode in 36590 steps, reward 154.00\n",
      "544 Episode in 36741 steps, reward 151.00\n",
      "545 Episode in 36885 steps, reward 144.00\n",
      "546 Episode in 37039 steps, reward 154.00\n",
      "547 Episode in 37185 steps, reward 146.00\n",
      "548 Episode in 37313 steps, reward 128.00\n",
      "549 Episode in 37441 steps, reward 128.00\n",
      "550 Episode in 37572 steps, reward 131.00\n",
      "551 Episode in 37704 steps, reward 132.00\n",
      "552 Episode in 37841 steps, reward 137.00\n",
      "553 Episode in 37974 steps, reward 133.00\n",
      "554 Episode in 38114 steps, reward 140.00\n",
      "555 Episode in 38250 steps, reward 136.00\n",
      "556 Episode in 38393 steps, reward 143.00\n",
      "557 Episode in 38535 steps, reward 142.00\n",
      "558 Episode in 38668 steps, reward 133.00\n",
      "559 Episode in 38812 steps, reward 144.00\n",
      "560 Episode in 38958 steps, reward 146.00\n",
      "561 Episode in 39092 steps, reward 134.00\n",
      "562 Episode in 39227 steps, reward 135.00\n",
      "563 Episode in 39372 steps, reward 145.00\n",
      "564 Episode in 39515 steps, reward 143.00\n",
      "565 Episode in 39669 steps, reward 154.00\n",
      "566 Episode in 39829 steps, reward 160.00\n",
      "567 Episode in 39991 steps, reward 162.00\n",
      "568 Episode in 40164 steps, reward 173.00\n",
      "569 Episode in 40336 steps, reward 172.00\n",
      "570 Episode in 40493 steps, reward 157.00\n",
      "571 Episode in 40644 steps, reward 151.00\n",
      "572 Episode in 40780 steps, reward 136.00\n",
      "573 Episode in 40931 steps, reward 151.00\n",
      "574 Episode in 41076 steps, reward 145.00\n",
      "575 Episode in 41217 steps, reward 141.00\n",
      "576 Episode in 41359 steps, reward 142.00\n",
      "577 Episode in 41526 steps, reward 167.00\n",
      "578 Episode in 41662 steps, reward 136.00\n",
      "579 Episode in 41807 steps, reward 145.00\n",
      "580 Episode in 41947 steps, reward 140.00\n",
      "581 Episode in 42093 steps, reward 146.00\n",
      "582 Episode in 42236 steps, reward 143.00\n",
      "583 Episode in 42377 steps, reward 141.00\n",
      "584 Episode in 42520 steps, reward 143.00\n",
      "585 Episode in 42673 steps, reward 153.00\n",
      "586 Episode in 42819 steps, reward 146.00\n",
      "587 Episode in 42960 steps, reward 141.00\n",
      "588 Episode in 43098 steps, reward 138.00\n",
      "589 Episode in 43238 steps, reward 140.00\n",
      "590 Episode in 43371 steps, reward 133.00\n",
      "591 Episode in 43515 steps, reward 144.00\n",
      "592 Episode in 43653 steps, reward 138.00\n",
      "593 Episode in 43801 steps, reward 148.00\n",
      "594 Episode in 43959 steps, reward 158.00\n",
      "595 Episode in 44131 steps, reward 172.00\n",
      "596 Episode in 44290 steps, reward 159.00\n",
      "597 Episode in 44441 steps, reward 151.00\n",
      "598 Episode in 44592 steps, reward 151.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "599 Episode in 44753 steps, reward 161.00\n",
      "600 Episode in 44905 steps, reward 152.00\n",
      "601 Episode in 45047 steps, reward 142.00\n",
      "602 Episode in 45184 steps, reward 137.00\n",
      "603 Episode in 45318 steps, reward 134.00\n",
      "604 Episode in 45484 steps, reward 166.00\n",
      "605 Episode in 45629 steps, reward 145.00\n",
      "606 Episode in 45766 steps, reward 137.00\n",
      "607 Episode in 45907 steps, reward 141.00\n",
      "608 Episode in 46050 steps, reward 143.00\n",
      "609 Episode in 46182 steps, reward 132.00\n",
      "610 Episode in 46322 steps, reward 140.00\n",
      "611 Episode in 46473 steps, reward 151.00\n",
      "612 Episode in 46618 steps, reward 145.00\n",
      "613 Episode in 46766 steps, reward 148.00\n",
      "614 Episode in 46905 steps, reward 139.00\n",
      "615 Episode in 47038 steps, reward 133.00\n",
      "616 Episode in 47169 steps, reward 131.00\n",
      "617 Episode in 47296 steps, reward 127.00\n",
      "618 Episode in 47429 steps, reward 133.00\n",
      "619 Episode in 47567 steps, reward 138.00\n",
      "620 Episode in 47704 steps, reward 137.00\n",
      "621 Episode in 47840 steps, reward 136.00\n",
      "622 Episode in 47981 steps, reward 141.00\n",
      "623 Episode in 48131 steps, reward 150.00\n",
      "624 Episode in 48301 steps, reward 170.00\n",
      "625 Episode in 48446 steps, reward 145.00\n",
      "626 Episode in 48612 steps, reward 166.00\n",
      "627 Episode in 48786 steps, reward 174.00\n",
      "628 Episode in 48947 steps, reward 161.00\n",
      "629 Episode in 49097 steps, reward 150.00\n",
      "630 Episode in 49235 steps, reward 138.00\n",
      "631 Episode in 49382 steps, reward 147.00\n",
      "632 Episode in 49516 steps, reward 134.00\n",
      "633 Episode in 49667 steps, reward 151.00\n",
      "634 Episode in 49817 steps, reward 150.00\n",
      "635 Episode in 49984 steps, reward 167.00\n",
      "636 Episode in 50137 steps, reward 153.00\n",
      "637 Episode in 50302 steps, reward 165.00\n",
      "638 Episode in 50454 steps, reward 152.00\n",
      "639 Episode in 50640 steps, reward 186.00\n",
      "640 Episode in 50826 steps, reward 186.00\n",
      "641 Episode in 50991 steps, reward 165.00\n",
      "642 Episode in 51157 steps, reward 166.00\n",
      "643 Episode in 51330 steps, reward 173.00\n"
     ]
    }
   ],
   "source": [
    "# play\n",
    "for i in range(1, n_episodes + 1):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    ep_reward = 0\n",
    "    while not done:\n",
    "#         env.render()\n",
    "        if np.random.rand() < epsilon:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            action = select_action(obs, target_net)\n",
    "\n",
    "        _obs, reward, done, _ = env.step(action)\n",
    "\n",
    "        rep_memory.append((obs, action, reward, _obs, done))\n",
    "\n",
    "        obs = _obs\n",
    "        total_steps += 1\n",
    "        ep_reward += reward\n",
    "\n",
    "        if use_eps_decay:\n",
    "            epsilon -= epsilon * decay_rate\n",
    "            epsilon = max(eps_min, epsilon)\n",
    "\n",
    "        if len(rep_memory) >= learn_start:\n",
    "            if len(rep_memory) == learn_start:\n",
    "                print('\\n============  Start Learning  ============\\n')\n",
    "            learn(net, target_net, optimizer, rep_memory)\n",
    "            learn_steps += 1\n",
    "\n",
    "        if learn_steps == update_frq:\n",
    "            # target smoothing update\n",
    "            with torch.no_grad():\n",
    "                for t, n in zip(target_net.parameters(), net.parameters()):\n",
    "                    t.data = UP_COEF * n.data + (1 - UP_COEF) * t.data\n",
    "                learn_steps = 0\n",
    "\n",
    "    if done:\n",
    "        rewards.append(ep_reward)\n",
    "        reward_eval.append(ep_reward)\n",
    "        print('{:3} Episode in {:5} steps, reward {:.2f}'.format(\n",
    "            i, total_steps, ep_reward))\n",
    "\n",
    "        if len(reward_eval) >= n_eval:\n",
    "            if np.mean(reward_eval) >= env.spec.reward_threshold:\n",
    "                print('\\n{} is sloved! {:3} Episode in {:3} steps'.format(\n",
    "                    env.spec.id, i, total_steps))\n",
    "                torch.save(target_net.state_dict(),\n",
    "                           f'./test/saved_models/{env.spec.id}_ep{i}_clear_model_cdqn.pt')\n",
    "                break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.title('Reward')\n",
    "plt.plot(rewards)\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.title('Loss')\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    ('CartPole-v0', 215, 0.25),\n",
    "    ('CartPole-v1', 291, 0.1),\n",
    "    ('MountainCar-v0', None, 0.1),\n",
    "    ('LunarLander-v2', None, 0.1)\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "C51_tensorflow.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
