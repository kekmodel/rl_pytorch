{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IWnm3qot3o1W"
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "import gym\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions import Categorical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Ffkl_5C4R81"
   },
   "outputs": [],
   "source": [
    "class ActorCriticNet(nn.Module):\n",
    "    def __init__(self, obs_space, action_space):\n",
    "        super().__init__()\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(obs_space, 256),\n",
    "            nn.SELU()\n",
    "        )\n",
    "\n",
    "        self.pol = nn.Sequential(\n",
    "            nn.Linear(256, 256),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(256, action_space)\n",
    "        )\n",
    "        \n",
    "        self.val = nn.Sequential(\n",
    "            nn.Linear(256, 256),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "        \n",
    "        self.log_softmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.head(x)\n",
    "        logit = self.pol(out).reshape(out.shape[0], -1)\n",
    "        value = self.val(out).reshape(out.shape[0], 1)\n",
    "        log_probs = self.log_softmax(logit)\n",
    "        \n",
    "        return log_probs, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action_and_value(obs, old_net):\n",
    "    old_net.eval()\n",
    "    with torch.no_grad():\n",
    "        state = torch.tensor([obs]).to(device).float()\n",
    "        log_p, v = old_net(state)\n",
    "        m = Categorical(log_p.exp())\n",
    "        action = m.sample()\n",
    "\n",
    "    return action.item(), v.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3377
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 135196,
     "status": "ok",
     "timestamp": 1534482559393,
     "user": {
      "displayName": "윤승제",
      "photoUrl": "//lh5.googleusercontent.com/-EucKC7DmcQI/AAAAAAAAAAI/AAAAAAAAAGA/gQU1NPEmNFA/s50-c-k-no/photo.jpg",
      "userId": "105654037995838004821"
     },
     "user_tz": -540
    },
    "id": "PnifSBJglzHh",
    "outputId": "94177345-918e-4a96-d9a8-d8aba0a4bc9a",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# make an environment\n",
    "# env = gym.make('CartPole-v0')\n",
    "env = gym.make('CartPole-v1')\n",
    "# env = gym.make('MountainCar-v0')\n",
    "# env = gym.make('LunarLander-v2')\n",
    "\n",
    "SEED = 0\n",
    "env.seed(SEED)\n",
    "obs_space = env.observation_space.shape[0]\n",
    "action_space = env.action_space.n\n",
    "\n",
    "# hyperparameter\n",
    "n_episodes = 1000\n",
    "n_eval = env.spec.trials\n",
    "\n",
    "# global values\n",
    "total_steps = 0\n",
    "rewards = []\n",
    "reward_eval = deque(maxlen=n_eval)\n",
    "is_solved = False\n",
    "\n",
    "# load a model\n",
    "target_net = ActorCriticNet(obs_space, action_space).to(device)\n",
    "target_net.load_state_dict(torch.load(\n",
    "    './saved_models/CartPole-v1_ep225_clear_model_ppo.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.spec.max_episode_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.spec.trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "475.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.spec.reward_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.metadata['video.frames_per_second'] = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3377
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 135196,
     "status": "ok",
     "timestamp": 1534482559393,
     "user": {
      "displayName": "윤승제",
      "photoUrl": "//lh5.googleusercontent.com/-EucKC7DmcQI/AAAAAAAAAAI/AAAAAAAAAGA/gQU1NPEmNFA/s50-c-k-no/photo.jpg",
      "userId": "105654037995838004821"
     },
     "user_tz": -540
    },
    "id": "PnifSBJglzHh",
    "outputId": "94177345-918e-4a96-d9a8-d8aba0a4bc9a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1 Episode in   500 steps, reward 500.00\n",
      "  2 Episode in  1000 steps, reward 500.00\n",
      "  3 Episode in  1500 steps, reward 500.00\n",
      "  4 Episode in  2000 steps, reward 500.00\n",
      "  5 Episode in  2500 steps, reward 500.00\n",
      "  6 Episode in  3000 steps, reward 500.00\n",
      "  7 Episode in  3500 steps, reward 500.00\n",
      "  8 Episode in  4000 steps, reward 500.00\n",
      "  9 Episode in  4500 steps, reward 500.00\n",
      " 10 Episode in  5000 steps, reward 500.00\n",
      " 11 Episode in  5500 steps, reward 500.00\n",
      " 12 Episode in  6000 steps, reward 500.00\n",
      " 13 Episode in  6500 steps, reward 500.00\n",
      " 14 Episode in  7000 steps, reward 500.00\n",
      " 15 Episode in  7500 steps, reward 500.00\n",
      " 16 Episode in  8000 steps, reward 500.00\n",
      " 17 Episode in  8500 steps, reward 500.00\n",
      " 18 Episode in  9000 steps, reward 500.00\n",
      " 19 Episode in  9500 steps, reward 500.00\n",
      " 20 Episode in 10000 steps, reward 500.00\n",
      " 21 Episode in 10500 steps, reward 500.00\n",
      " 22 Episode in 11000 steps, reward 500.00\n",
      " 23 Episode in 11500 steps, reward 500.00\n",
      " 24 Episode in 12000 steps, reward 500.00\n",
      " 25 Episode in 12500 steps, reward 500.00\n",
      " 26 Episode in 13000 steps, reward 500.00\n",
      " 27 Episode in 13500 steps, reward 500.00\n",
      " 28 Episode in 14000 steps, reward 500.00\n",
      " 29 Episode in 14500 steps, reward 500.00\n",
      " 30 Episode in 15000 steps, reward 500.00\n",
      " 31 Episode in 15500 steps, reward 500.00\n",
      " 32 Episode in 16000 steps, reward 500.00\n",
      " 33 Episode in 16500 steps, reward 500.00\n",
      " 34 Episode in 17000 steps, reward 500.00\n",
      " 35 Episode in 17500 steps, reward 500.00\n",
      " 36 Episode in 18000 steps, reward 500.00\n",
      " 37 Episode in 18500 steps, reward 500.00\n",
      " 38 Episode in 19000 steps, reward 500.00\n",
      " 39 Episode in 19500 steps, reward 500.00\n",
      " 40 Episode in 20000 steps, reward 500.00\n",
      " 41 Episode in 20500 steps, reward 500.00\n",
      " 42 Episode in 21000 steps, reward 500.00\n",
      " 43 Episode in 21500 steps, reward 500.00\n",
      " 44 Episode in 22000 steps, reward 500.00\n",
      " 45 Episode in 22500 steps, reward 500.00\n",
      " 46 Episode in 23000 steps, reward 500.00\n",
      " 47 Episode in 23500 steps, reward 500.00\n",
      " 48 Episode in 24000 steps, reward 500.00\n",
      " 49 Episode in 24500 steps, reward 500.00\n",
      " 50 Episode in 25000 steps, reward 500.00\n",
      " 51 Episode in 25500 steps, reward 500.00\n",
      " 52 Episode in 26000 steps, reward 500.00\n",
      " 53 Episode in 26500 steps, reward 500.00\n",
      " 54 Episode in 27000 steps, reward 500.00\n",
      " 55 Episode in 27500 steps, reward 500.00\n",
      " 56 Episode in 28000 steps, reward 500.00\n",
      " 57 Episode in 28500 steps, reward 500.00\n",
      " 58 Episode in 29000 steps, reward 500.00\n",
      " 59 Episode in 29500 steps, reward 500.00\n",
      " 60 Episode in 30000 steps, reward 500.00\n",
      " 61 Episode in 30500 steps, reward 500.00\n",
      " 62 Episode in 31000 steps, reward 500.00\n",
      " 63 Episode in 31500 steps, reward 500.00\n",
      " 64 Episode in 32000 steps, reward 500.00\n",
      " 65 Episode in 32500 steps, reward 500.00\n",
      " 66 Episode in 33000 steps, reward 500.00\n",
      " 67 Episode in 33500 steps, reward 500.00\n",
      " 68 Episode in 34000 steps, reward 500.00\n",
      " 69 Episode in 34500 steps, reward 500.00\n",
      " 70 Episode in 35000 steps, reward 500.00\n",
      " 71 Episode in 35500 steps, reward 500.00\n",
      " 72 Episode in 36000 steps, reward 500.00\n",
      " 73 Episode in 36500 steps, reward 500.00\n",
      " 74 Episode in 37000 steps, reward 500.00\n",
      " 75 Episode in 37500 steps, reward 500.00\n",
      " 76 Episode in 38000 steps, reward 500.00\n",
      " 77 Episode in 38500 steps, reward 500.00\n",
      " 78 Episode in 39000 steps, reward 500.00\n",
      " 79 Episode in 39500 steps, reward 500.00\n",
      " 80 Episode in 40000 steps, reward 500.00\n",
      " 81 Episode in 40500 steps, reward 500.00\n",
      " 82 Episode in 41000 steps, reward 500.00\n",
      " 83 Episode in 41500 steps, reward 500.00\n",
      " 84 Episode in 42000 steps, reward 500.00\n",
      " 85 Episode in 42500 steps, reward 500.00\n",
      " 86 Episode in 43000 steps, reward 500.00\n",
      " 87 Episode in 43500 steps, reward 500.00\n",
      " 88 Episode in 44000 steps, reward 500.00\n",
      " 89 Episode in 44500 steps, reward 500.00\n",
      " 90 Episode in 45000 steps, reward 500.00\n",
      " 91 Episode in 45500 steps, reward 500.00\n",
      " 92 Episode in 46000 steps, reward 500.00\n",
      " 93 Episode in 46500 steps, reward 500.00\n",
      " 94 Episode in 47000 steps, reward 500.00\n",
      " 95 Episode in 47500 steps, reward 500.00\n",
      " 96 Episode in 48000 steps, reward 500.00\n",
      " 97 Episode in 48500 steps, reward 500.00\n",
      " 98 Episode in 49000 steps, reward 500.00\n",
      " 99 Episode in 49500 steps, reward 500.00\n",
      "100 Episode in 50000 steps, reward 500.00\n",
      "\n",
      "CartPole-v1 is sloved! 100 Episode in 50000 steps\n",
      "500.0\n"
     ]
    }
   ],
   "source": [
    "# play\n",
    "# frames = []\n",
    "for i in range(1, n_episodes + 1):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    ep_reward = 0\n",
    "    while not done:\n",
    "#         frames.append(env.render(mode = 'rgb_array'))\n",
    "        env.render()\n",
    "        action, _ = get_action_and_value(obs, target_net)\n",
    "        _obs, reward, done, _ = env.step(action)\n",
    "        obs = _obs\n",
    "        total_steps += 1\n",
    "        ep_reward += reward     \n",
    "    if done:\n",
    "        env.render()\n",
    "        rewards.append(ep_reward)\n",
    "        reward_eval.append(ep_reward)\n",
    "        print('{:3} Episode in {:5} steps, reward {:.2f}'.format(\n",
    "            i, total_steps, ep_reward))\n",
    "#         frames.append(env.render(mode = 'rgb_array'))\n",
    "#         imageio.mimsave(f'{env.spec.id}.gif', frames,)\n",
    "        \n",
    "        if len(reward_eval) >= n_eval:\n",
    "            if np.mean(reward_eval) >= env.spec.reward_threshold:\n",
    "                print('\\n{} is sloved! {:3} Episode in {:3} steps'.format(\n",
    "                    env.spec.id, i, total_steps))\n",
    "                print(np.mean(reward_eval))\n",
    "                break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.title('reward')\n",
    "plt.plot(rewards)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CartPole-v0', 412, 1),\n",
       " ('CartPole-v1', 452, 0.05),\n",
       " ('MountainCar-v0', 193, 0.1),\n",
       " ('LunarLander-v2', 260, 0.1)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "    ('CartPole-v0', 412, 1),\n",
    "    ('CartPole-v1', 452, 0.05),\n",
    "    ('MountainCar-v0', 193, 0.1),\n",
    "    ('LunarLander-v2', 260, 0.1)\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "C51_tensorflow.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
