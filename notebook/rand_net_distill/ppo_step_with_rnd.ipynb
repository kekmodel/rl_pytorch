{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IWnm3qot3o1W"
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from copy import deepcopy\n",
    "\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 708,
     "status": "ok",
     "timestamp": 1534482400648,
     "user": {
      "displayName": "윤승제",
      "photoUrl": "//lh5.googleusercontent.com/-EucKC7DmcQI/AAAAAAAAAAI/AAAAAAAAAGA/gQU1NPEmNFA/s50-c-k-no/photo.jpg",
      "userId": "105654037995838004821"
     },
     "user_tz": -540
    },
    "id": "maRVADiTlzHD",
    "outputId": "783b7610-95c2-4b54-b2ce-d8e853c484ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda: True\n"
     ]
    }
   ],
   "source": [
    "SEED = 1\n",
    "BATCH_SIZE = 8\n",
    "LR = 0.00030\n",
    "EPOCHS = 4\n",
    "CLIP = 0.1\n",
    "UP_PROP = 0.25\n",
    "GAMMA_EX = 0.999\n",
    "GAMMA_IN = 0.99\n",
    "LAMBDA = 0.95\n",
    "ENT_COEF = 0.001\n",
    "EX_COEF = 2.0\n",
    "IN_COEF = 1.0\n",
    "V_CLIP = True\n",
    "EPS = np.finfo(np.float).eps\n",
    "\n",
    "# set device\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print('cuda:', use_cuda)\n",
    "device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "\n",
    "# random seed\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Ffkl_5C4R81"
   },
   "outputs": [],
   "source": [
    "class ActorCriticNet(nn.Module):\n",
    "    def __init__(self, obs_space, action_space):\n",
    "        super().__init__()\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(obs_space, obs_space*10),\n",
    "            nn.SELU()\n",
    "        )\n",
    "        self.pol = nn.Sequential(\n",
    "            nn.Linear(obs_space*10, 512),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(512, action_space)\n",
    "        )\n",
    "        self.val_ex = nn.Sequential(\n",
    "            nn.Linear(obs_space*10, 512),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(512, 1)\n",
    "        )\n",
    "        self.val_in = nn.Sequential(\n",
    "            nn.Linear(obs_space*10, 512),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(512, 1)\n",
    "        )\n",
    "        self.log_softmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.head(x)\n",
    "        logit = self.pol(out).reshape(out.shape[0], -1)\n",
    "        value_ex = self.val_ex(out).reshape(out.shape[0], 1)\n",
    "        value_in = self.val_in(out).reshape(out.shape[0], 1)\n",
    "        log_probs = self.log_softmax(logit)\n",
    "        \n",
    "        return log_probs, value_ex, value_in\n",
    "    \n",
    "\n",
    "class RandomNet(nn.Module):\n",
    "    def __init__(self, obs_space):\n",
    "        super().__init__()\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(obs_space, obs_space*10),\n",
    "            nn.SELU()\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(obs_space*10, 512)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.head(x)\n",
    "        obs_feature = self.fc(out).reshape(out.shape[0], -1)\n",
    "\n",
    "        return obs_feature\n",
    "\n",
    "\n",
    "class PredictNet(nn.Module):\n",
    "    def __init__(self, obs_space):\n",
    "        super().__init__()\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(obs_space, obs_space*10),\n",
    "            nn.SELU()\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(obs_space*10, 512),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(512, 512)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.head(x)\n",
    "        obs_feature = self.fc(out).reshape(out.shape[0], -1)\n",
    "\n",
    "        return obs_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "m_losses = []\n",
    "f_losses = []\n",
    "\n",
    "\n",
    "def learn(net, old_net, pred_net, rand_net, optimizer, train_memory):\n",
    "    global CLIP\n",
    "    net.train()\n",
    "    old_net.train()\n",
    "\n",
    "    for i in range(EPOCHS):\n",
    "        dataloader = DataLoader(\n",
    "            train_memory,\n",
    "            shuffle=True,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            pin_memory=use_cuda\n",
    "        )\n",
    "        for (s, a, _s, ret_ex, ret_in, adv_ex, adv_in) in dataloader:\n",
    "            s = s.to(device).float()\n",
    "#             s_norm_np = normalize_obs(s.detach().cpu().numpy())\n",
    "#             s_norm = torch.tensor(s_norm_np, requires_grad=True).to(device).float()\n",
    "            a  = a.to(device).long()\n",
    "            _s = _s.to(device).float()\n",
    "            _s_norm_np = normalize_obs(_s.detach().cpu().numpy())\n",
    "            _s_norm = torch.tensor(_s_norm_np, requires_grad=True).to(device).float()\n",
    "            ret_ex = ret_ex.to(device).float()\n",
    "            ret_in = ret_in.to(device).float()\n",
    "            adv = (adv_ex + adv_in).to(device).float()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                rand_f = rand_net(_s_norm)\n",
    "                log_p_old, v_ex_old, v_in_old = old_net(s)\n",
    "                log_p_a_old = log_p_old[range(BATCH_SIZE), a]\n",
    "\n",
    "            pred_f = pred_net(_s_norm)\n",
    "            log_p, v_ex, v_in = net(s)\n",
    "            log_p_a = log_p[range(BATCH_SIZE), a]\n",
    "            p_ratio = (log_p_a - log_p_a_old).exp()\n",
    "            p_r_clip = torch.clamp(p_ratio, 1. - CLIP, 1. + CLIP)\n",
    "            p_loss = torch.min(p_ratio * adv, p_r_clip * adv).mean()\n",
    "            \n",
    "            if V_CLIP:\n",
    "                v_ex_clip = v_ex_old + \\\n",
    "                    torch.clamp(v_ex - v_ex_old, -CLIP, CLIP)\n",
    "                v_ex_loss1 = (ret_ex - v_ex_clip).pow(2)\n",
    "                v_ex_loss2 = (ret_ex - v_ex).pow(2)\n",
    "                v_ex_loss = 0.5 * torch.max(v_ex_loss1, v_ex_loss2)\n",
    "                v_in_clip = v_in_old + \\\n",
    "                    torch.clamp(v_in - v_in_old, -CLIP, CLIP)\n",
    "                v_in_loss1 = (ret_in - v_in_clip).pow(2)\n",
    "                v_in_loss2 = (ret_in - v_in).pow(2)\n",
    "                v_in_loss = 0.5 * torch.max(v_in_loss1, v_in_loss2)\n",
    "            else:\n",
    "                v_ex_loss = 0.5 * (ret_ex - v_ex).pow(2)\n",
    "                v_in_loss = 0.5 * (ret_in - v_in).pow(2)\n",
    "            \n",
    "            v_loss = (v_ex_loss + v_in_loss).mean() \n",
    "            m = Categorical(log_p.exp())\n",
    "            entropy = m.entropy().mean()\n",
    "\n",
    "            # loss\n",
    "            m_loss = -(p_loss - 0.5 * v_loss + ENT_COEF * entropy)\n",
    "            m_losses.append(m_loss)\n",
    "\n",
    "            f_loss = (pred_f - rand_f).pow(2)\n",
    "            mask = torch.rand(f_loss.shape[1]).to(device)\n",
    "            mask = (mask < UP_PROP).to(device).float()\n",
    "            f_loss = (f_loss * mask).sum() / mask.sum().clamp(min=1)\n",
    "            f_losses.append(f_loss)\n",
    "            \n",
    "            loss = m_loss + f_loss\n",
    "            losses.append(loss)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(total_params, max_norm=0.5)\n",
    "            optimizer.step()\n",
    "\n",
    "#         CLIP = max(CLIP * 0.999, 0.0001)\n",
    "    train_memory.clear()\n",
    "\n",
    "\n",
    "def get_action_and_value(obs, old_net):\n",
    "    old_net.eval()\n",
    "    with torch.no_grad():\n",
    "        state = torch.tensor([obs]).to(device).float()\n",
    "        log_p, v_ex, v_in = old_net(state)\n",
    "        m = Categorical(log_p.exp())\n",
    "        action = m.sample()\n",
    "\n",
    "    return action.item(), v_ex.item(), v_in.item()\n",
    "\n",
    "\n",
    "def compute_adv_with_gae(rews_ex, rews_in, vals_ex, vals_in, roll_memory):\n",
    "    rew_ex = np.array(rews_ex, 'float')\n",
    "    rew_in = np.array(rews_in, 'float')\n",
    "    val_ex = np.array(vals_ex[:-1], 'float')\n",
    "    val_in = np.array(vals_in[:-1], 'float')\n",
    "    _val_ex = np.array(vals_ex[1:], 'float')\n",
    "    _val_in = np.array(vals_in[1:], 'float')\n",
    "    dt_ex = rew_ex + GAMMA_EX * _val_ex - val_ex\n",
    "    dt_in = rew_in + GAMMA_IN * _val_in - val_in\n",
    "    dis_r_ex = np.array([GAMMA_EX**(i) * r for i, r in enumerate(rews_ex)], 'float')\n",
    "    dis_r_in = np.array([GAMMA_IN**(i) * r for i, r in enumerate(rews_in)], 'float')\n",
    "    gae_ex = np.array([(GAMMA_EX * LAMBDA)**(i) * dt for i, dt in enumerate(dt_ex.tolist())], 'float')\n",
    "    gae_in = np.array([(GAMMA_IN * LAMBDA)**(i) * dt for i, dt in enumerate(dt_in.tolist())], 'float')\n",
    "    for i, data in enumerate(roll_memory):\n",
    "        data.append(sum(dis_r_ex[i:] / GAMMA_EX**(i)))\n",
    "        data.append(sum(dis_r_in[i:] / GAMMA_IN**(i)))\n",
    "        data.append(sum(gae_ex[i:] / (GAMMA_EX * LAMBDA)**(i)))\n",
    "        data.append(sum(gae_in[i:] / (GAMMA_IN * LAMBDA)**(i)))\n",
    "    rews_ex.clear()\n",
    "    rews_in.clear()\n",
    "    vals_ex.clear()\n",
    "    vals_in.clear()\n",
    "\n",
    "    return roll_memory\n",
    "\n",
    "\n",
    "def get_norm_params(obs_memory):\n",
    "    global obs_apace\n",
    "\n",
    "    obses = [[] for _ in range(obs_space)]\n",
    "    for obs in obs_memory:\n",
    "        for j in range(obs_space):\n",
    "            obses[j].append(obs[j])\n",
    "\n",
    "    mean = np.zeros(obs_space, 'float')\n",
    "    std = np.zeros(obs_space, 'float')\n",
    "    for i, obs_ in enumerate(obses):\n",
    "        mean[i] = np.mean(obs_)\n",
    "        std[i] = np.std(obs_)\n",
    "    obs_memory.clear()\n",
    "\n",
    "    return mean, np.clip(std, a_min=EPS, a_max=None)\n",
    "\n",
    "\n",
    "def normalize_obs(obs):\n",
    "    global mean, std\n",
    "    norm_obs = (obs - mean) / std\n",
    "\n",
    "    return np.clip(norm_obs, -5, 5)\n",
    "\n",
    "\n",
    "def calculate_reward_in(pred_net, rand_net, obs):\n",
    "    norm_obs = normalize_obs(obs)\n",
    "    state = torch.tensor([norm_obs]).to(device).float()\n",
    "    with torch.no_grad():\n",
    "        pred_obs = pred_net(state)\n",
    "        rand_obs = rand_net(state)\n",
    "        reward = (pred_obs - rand_obs).pow(2).sum()\n",
    "        clipped_reward = torch.clamp(reward, -1, 1)\n",
    "\n",
    "    return clipped_reward.item()\n",
    "\n",
    "\n",
    "def simulation(env):\n",
    "    global mean, std\n",
    "    init_steps = 0\n",
    "    obs_mem = []\n",
    "    while True:\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "    #         env.render()\n",
    "            action = env.action_space.sample()\n",
    "            _obs, _, done, _ = env.step(action)\n",
    "            obs_mem.append(_obs)\n",
    "            init_steps += 1\n",
    "            if init_steps == 1000000:\n",
    "                mean, std = get_norm_params(obs_mem)\n",
    "                done = True\n",
    "        if done:\n",
    "            if init_steps == 1000000:\n",
    "                env.close()\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3377
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 135196,
     "status": "ok",
     "timestamp": 1534482559393,
     "user": {
      "displayName": "윤승제",
      "photoUrl": "//lh5.googleusercontent.com/-EucKC7DmcQI/AAAAAAAAAAI/AAAAAAAAAGA/gQU1NPEmNFA/s50-c-k-no/photo.jpg",
      "userId": "105654037995838004821"
     },
     "user_tz": -540
    },
    "id": "PnifSBJglzHh",
    "outputId": "94177345-918e-4a96-d9a8-d8aba0a4bc9a",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jay/anaconda3/lib/python3.7/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    }
   ],
   "source": [
    "# make an environment\n",
    "# env = gym.make('CartPole-v0')\n",
    "# env = gym.make('CartPole-v1')\n",
    "# env = gym.make('MountainCar-v0')\n",
    "env = gym.make('LunarLander-v2')\n",
    "\n",
    "env.seed(SEED)\n",
    "obs_space = env.observation_space.shape[0]\n",
    "action_space = env.action_space.n\n",
    "\n",
    "# hyperparameter\n",
    "n_episodes = 3000\n",
    "roll_len = 256\n",
    "n_eval = env.spec.trials\n",
    "\n",
    "# global values\n",
    "steps = 0\n",
    "mean = 0.\n",
    "std = 0.\n",
    "ep_rewards = []\n",
    "is_rollout = False\n",
    "is_solved = False\n",
    "\n",
    "# make a rollout memory\n",
    "net_memory = deque(maxlen=2)\n",
    "train_memory = []\n",
    "roll_memory = []\n",
    "obs_memory = []\n",
    "rews_ex = []\n",
    "rews_in = []\n",
    "vals_ex = []\n",
    "vals_in = []\n",
    "\n",
    "# make nerual networks\n",
    "net = ActorCriticNet(obs_space, action_space).to(device)\n",
    "old_net = deepcopy(net)\n",
    "net_memory.appendleft(net.state_dict())\n",
    "pred_net = PredictNet(obs_space).to(device)\n",
    "rand_net = RandomNet(obs_space).to(device)\n",
    "\n",
    "# make optimizer\n",
    "total_params = list(net.parameters()) + list(pred_net.parameters())\n",
    "optimizer = torch.optim.Adam(total_params, lr=LR, eps=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.spec.max_episode_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.spec.trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.spec.reward_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3377
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 135196,
     "status": "ok",
     "timestamp": 1534482559393,
     "user": {
      "displayName": "윤승제",
      "photoUrl": "//lh5.googleusercontent.com/-EucKC7DmcQI/AAAAAAAAAAI/AAAAAAAAAGA/gQU1NPEmNFA/s50-c-k-no/photo.jpg",
      "userId": "105654037995838004821"
     },
     "user_tz": -540
    },
    "id": "PnifSBJglzHh",
    "outputId": "94177345-918e-4a96-d9a8-d8aba0a4bc9a",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# play!\n",
    "simulation(env)\n",
    "for i in range(1, n_episodes + 1):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    ep_rew_ex = 0.\n",
    "    ep_rew_in = 0.\n",
    "    while not done:\n",
    "#         env.render()\n",
    "\n",
    "        action, val_ex, val_in = get_action_and_value(obs, old_net)\n",
    "        _obs, rew_ex, done, _ = env.step(action)\n",
    "        \n",
    "        rew_in = calculate_reward_in(pred_net, rand_net, _obs)    \n",
    "        \n",
    "        # store\n",
    "        roll_memory.append([obs, action, _obs])\n",
    "        obs_memory.append(_obs)\n",
    "        rews_ex.append(0.5 * EX_COEF * rew_ex)\n",
    "        rews_in.append(0.5 * IN_COEF * rew_in)\n",
    "        vals_ex.append(0.5 * val_ex)\n",
    "        vals_in.append(0.5 * val_in)\n",
    "        \n",
    "        obs = _obs\n",
    "        steps += 1\n",
    "        ep_rew_ex += rew_ex\n",
    "        ep_rew_in += rew_in\n",
    "        \n",
    "        if done or steps % roll_len == 0:\n",
    "            if done:\n",
    "                _val_ex = 0.\n",
    "                _val_in = 0.\n",
    "            else:\n",
    "                _, _val_ex, _val_in = get_action_and_value(_obs, old_net)\n",
    "            \n",
    "            vals_ex.append(_val_ex)\n",
    "            vals_in.append(_val_in)\n",
    "            train_memory.extend(\n",
    "                compute_adv_with_gae(rews_ex, rews_in, vals_ex, vals_in, roll_memory)\n",
    "            )\n",
    "            roll_memory.clear()\n",
    "            \n",
    "        if steps % roll_len == 0:\n",
    "            learn(net, old_net, pred_net, rand_net, optimizer, train_memory)\n",
    "            old_net.load_state_dict(net.state_dict())\n",
    "            mean, std = get_norm_params(obs_memory)\n",
    "    \n",
    "    if done:        \n",
    "        ep_rewards.append(ep_rew_ex)\n",
    "        print('{:3} Episode in {:5} steps, '\n",
    "              'reward_ex {:.2f}, reward_in {:.2f}'.format(i, steps, ep_rew_ex, ep_rew_in))\n",
    "        \n",
    "        if env.spec.id == 'MountainCar-v0' and ep_rew_ex > -200:\n",
    "            print('################################################################################ Wow!')\n",
    "        \n",
    "        if len(ep_rewards) >= n_eval:\n",
    "            if np.mean(list(reversed(ep_rewards))[: n_eval]) >= env.spec.reward_threshold:\n",
    "                print('\\n{} is sloved! '\n",
    "                      '{:3} Episode in {:3} steps'.format(env.spec.id, i, steps))\n",
    "                torch.save(net.state_dict(),\n",
    "                           f'../test/saved_models/{env.spec.id}_ep{i}_clear_model_ppo_r.pt')\n",
    "                break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.title('Reward')\n",
    "plt.plot(ep_rewards)\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.title('Loss')\n",
    "plt.plot(losses)\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.title('m_Loss')\n",
    "plt.plot(m_losses)\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.title('f_Loss')\n",
    "plt.plot(f_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    ('CartPole-v0', 161, 32, 256),\n",
    "    ('CartPole-v1', 161, 32, 256),\n",
    "    ('MountainCar-v0', None),\n",
    "    ('LunarLander-v2', None)\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "C51_tensorflow.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
