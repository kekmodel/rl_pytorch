{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IWnm3qot3o1W"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import deque\n",
    "from copy import deepcopy\n",
    "\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 708,
     "status": "ok",
     "timestamp": 1534482400648,
     "user": {
      "displayName": "윤승제",
      "photoUrl": "//lh5.googleusercontent.com/-EucKC7DmcQI/AAAAAAAAAAI/AAAAAAAAAGA/gQU1NPEmNFA/s50-c-k-no/photo.jpg",
      "userId": "105654037995838004821"
     },
     "user_tz": -540
    },
    "id": "maRVADiTlzHD",
    "outputId": "783b7610-95c2-4b54-b2ce-d8e853c484ba"
   },
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "BATCH_SIZE = 256\n",
    "LR = 0.0003\n",
    "UP_COEF = 0.05\n",
    "GAMMA = 0.99\n",
    "EPS = 1.1920929e-07\n",
    "V_MAX = 10\n",
    "V_MIN = -10\n",
    "N_ATOMS = 51\n",
    "DELTA_Z = (V_MAX - V_MIN) / (N_ATOMS - 1)\n",
    "\n",
    "# set device\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "\n",
    "# random seed\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1920929e-07"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Ffkl_5C4R81"
   },
   "outputs": [],
   "source": [
    "class CategoricalDuelingDQN(nn.Module):\n",
    "    def __init__(self, obs_space, action_space, n_atoms):\n",
    "        super().__init__()\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(obs_space, 256),\n",
    "            nn.SELU()\n",
    "        )\n",
    "\n",
    "        self.val = nn.Sequential(\n",
    "            nn.Linear(256, 256),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(256, n_atoms)\n",
    "        )\n",
    "\n",
    "        self.adv = nn.Sequential(\n",
    "            nn.Linear(256, 256),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(256, action_space * n_atoms)\n",
    "        )\n",
    "\n",
    "        self.log_softmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "        self.register_buffer(\n",
    "            'support', torch.arange(V_MIN, V_MAX + DELTA_Z, DELTA_Z))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.head(x)\n",
    "        val_out = self.val(out).reshape(out.shape[0], 1, N_ATOMS)\n",
    "        adv_out = self.adv(out).reshape(out.shape[0], -1, N_ATOMS)\n",
    "        adv_mean = adv_out.mean(dim=1, keepdim=True)\n",
    "        out = val_out + adv_out - adv_mean\n",
    "        out = self.log_softmax(out)\n",
    "        probs = out.exp()\n",
    "\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "\n",
    "\n",
    "def learn(net, tgt_net, optimizer, rep_memory):\n",
    "    net.train()\n",
    "    tgt_net.train()\n",
    "\n",
    "    dataloader = DataLoader(rep_memory,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            shuffle=True,\n",
    "                            pin_memory=use_cuda)\n",
    "    # like a double DQN\n",
    "    for i, (s, a, r, _s, d) in enumerate(dataloader):\n",
    "        if i > 0:\n",
    "            break\n",
    "        s_batch = s.to(device).float()\n",
    "        a_batch = a.detach().to(device).long()\n",
    "        _s_batch = _s.to(device).float()\n",
    "        r_batch = r.detach().to(device).float()\n",
    "        is_done = 1. - d.detach().to(device).float()\n",
    "\n",
    "        _p_batch = net(_s_batch)\n",
    "        _weights = _p_batch * net.support\n",
    "        _q_batch = _weights.sum(dim=2)\n",
    "        _a_batch = torch.argmax(_q_batch, dim=1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            _p_batch_tgt = tgt_net(_s_batch)\n",
    "        _p_best = _p_batch_tgt[range(BATCH_SIZE), _a_batch]\n",
    "        _p_proj = projection(_p_best, r_batch, is_done)\n",
    "\n",
    "        p_batch = net(s_batch)\n",
    "        p_acting = p_batch[range(BATCH_SIZE), a_batch.data]\n",
    "\n",
    "        # loss\n",
    "        loss = -(_p_proj * torch.clamp(p_acting, min=EPS).log()).sum(dim=1).mean()\n",
    "#         loss = -(_p_proj * (p_acting + EPS).log()).sum(dim=1).mean()\n",
    "        losses.append(loss)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "def projection(_p_best, r_batch, is_done):\n",
    "    with torch.no_grad():\n",
    "        _p_proj = np.zeros((BATCH_SIZE, N_ATOMS), dtype=np.float32)\n",
    "        r_batch_np = r_batch.cpu().numpy()\n",
    "        is_done_np = is_done.cpu().numpy()\n",
    "        _p_best_np = _p_best.cpu().numpy()\n",
    "        \n",
    "    batch_id = range(BATCH_SIZE)\n",
    "    for i in range(N_ATOMS):\n",
    "        z = np.clip(r_batch_np + GAMMA * (V_MIN + i * DELTA_Z) * is_done_np,\n",
    "                    V_MIN, V_MAX)\n",
    "        b = (z - V_MIN) / DELTA_Z\n",
    "        l = np.floor(b).astype(np.int64)\n",
    "        u = np.ceil(b).astype(np.int64)\n",
    "        \n",
    "        _p_proj[batch_id, l[batch_id]] += _p_best_np[batch_id, i] * (u - b)[batch_id]\n",
    "        _p_proj[batch_id, u[batch_id]] += _p_best_np[batch_id, i] * (b - l)[batch_id]\n",
    "        \n",
    "#     _p_proj = np.clip(_p_proj, EPS, None)\n",
    "#     _p_proj = _p_proj / _p_proj.sum(axis=1, keepdims=1)\n",
    "    return torch.tensor(_p_proj).to(device).float()\n",
    "\n",
    "\n",
    "def select_action(obs, tgt_net):\n",
    "    tgt_net.eval()\n",
    "    with torch.no_grad():\n",
    "        state = torch.tensor([obs]).to(device).float()\n",
    "        probs = target_net(state)\n",
    "        weights = probs * net.support\n",
    "        q = weights.sum(dim=2)\n",
    "        action = torch.argmax(q, dim=1)\n",
    "\n",
    "    return action.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3377
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 135196,
     "status": "ok",
     "timestamp": 1534482559393,
     "user": {
      "displayName": "윤승제",
      "photoUrl": "//lh5.googleusercontent.com/-EucKC7DmcQI/AAAAAAAAAAI/AAAAAAAAAGA/gQU1NPEmNFA/s50-c-k-no/photo.jpg",
      "userId": "105654037995838004821"
     },
     "user_tz": -540
    },
    "id": "PnifSBJglzHh",
    "outputId": "94177345-918e-4a96-d9a8-d8aba0a4bc9a",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# make an environment\n",
    "# env = gym.make('CartPole-v0')\n",
    "env = gym.make('CartPole-v1')\n",
    "# env = gym.make('MountainCar-v0')\n",
    "# env = gym.make('LunarLander-v2')\n",
    "\n",
    "env.seed(SEED)\n",
    "obs_space = env.observation_space.shape[0]\n",
    "action_space = env.action_space.n\n",
    "\n",
    "# hyperparameter\n",
    "n_episodes = 1000\n",
    "learn_start = 1500\n",
    "memory_size = 50000\n",
    "update_frq = 1\n",
    "use_eps_decay = False\n",
    "epsilon = 0.001\n",
    "eps_min = 0.001\n",
    "decay_rate = 0.0001\n",
    "n_eval = env.spec.trials\n",
    "\n",
    "# global values\n",
    "total_steps = 0\n",
    "learn_steps = 0\n",
    "rewards = []\n",
    "reward_eval = deque(maxlen=n_eval)\n",
    "is_learned = False\n",
    "is_solved = False\n",
    "\n",
    "# make two nerual networks\n",
    "net = CategoricalDuelingDQN(obs_space, action_space, N_ATOMS).to(device)\n",
    "target_net = deepcopy(net)\n",
    "\n",
    "# make a optimizer\n",
    "optimizer = optim.Adam(net.parameters(), lr=LR, eps=EPS)\n",
    "\n",
    "# make memory\n",
    "rep_memory = deque(maxlen=memory_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.spec.max_episode_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.spec.trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "475.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.spec.reward_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3377
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 135196,
     "status": "ok",
     "timestamp": 1534482559393,
     "user": {
      "displayName": "윤승제",
      "photoUrl": "//lh5.googleusercontent.com/-EucKC7DmcQI/AAAAAAAAAAI/AAAAAAAAAGA/gQU1NPEmNFA/s50-c-k-no/photo.jpg",
      "userId": "105654037995838004821"
     },
     "user_tz": -540
    },
    "id": "PnifSBJglzHh",
    "outputId": "94177345-918e-4a96-d9a8-d8aba0a4bc9a",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1 Episode in    10 steps, reward 10.00\n",
      "  2 Episode in    18 steps, reward 8.00\n",
      "  3 Episode in    28 steps, reward 10.00\n",
      "  4 Episode in    38 steps, reward 10.00\n",
      "  5 Episode in    48 steps, reward 10.00\n",
      "  6 Episode in    58 steps, reward 10.00\n",
      "  7 Episode in    67 steps, reward 9.00\n",
      "  8 Episode in    78 steps, reward 11.00\n",
      "  9 Episode in    88 steps, reward 10.00\n",
      " 10 Episode in    98 steps, reward 10.00\n",
      " 11 Episode in   107 steps, reward 9.00\n",
      " 12 Episode in   115 steps, reward 8.00\n",
      " 13 Episode in   124 steps, reward 9.00\n",
      " 14 Episode in   133 steps, reward 9.00\n",
      " 15 Episode in   143 steps, reward 10.00\n",
      " 16 Episode in   153 steps, reward 10.00\n",
      " 17 Episode in   163 steps, reward 10.00\n",
      " 18 Episode in   172 steps, reward 9.00\n",
      " 19 Episode in   181 steps, reward 9.00\n",
      " 20 Episode in   190 steps, reward 9.00\n",
      " 21 Episode in   198 steps, reward 8.00\n",
      " 22 Episode in   207 steps, reward 9.00\n",
      " 23 Episode in   215 steps, reward 8.00\n",
      " 24 Episode in   226 steps, reward 11.00\n",
      " 25 Episode in   236 steps, reward 10.00\n",
      " 26 Episode in   245 steps, reward 9.00\n",
      " 27 Episode in   254 steps, reward 9.00\n",
      " 28 Episode in   263 steps, reward 9.00\n",
      " 29 Episode in   273 steps, reward 10.00\n",
      " 30 Episode in   282 steps, reward 9.00\n",
      " 31 Episode in   291 steps, reward 9.00\n",
      " 32 Episode in   301 steps, reward 10.00\n",
      " 33 Episode in   310 steps, reward 9.00\n",
      " 34 Episode in   318 steps, reward 8.00\n",
      " 35 Episode in   326 steps, reward 8.00\n",
      " 36 Episode in   334 steps, reward 8.00\n",
      " 37 Episode in   343 steps, reward 9.00\n",
      " 38 Episode in   353 steps, reward 10.00\n",
      " 39 Episode in   363 steps, reward 10.00\n",
      " 40 Episode in   373 steps, reward 10.00\n",
      " 41 Episode in   382 steps, reward 9.00\n",
      " 42 Episode in   392 steps, reward 10.00\n",
      " 43 Episode in   402 steps, reward 10.00\n",
      " 44 Episode in   412 steps, reward 10.00\n",
      " 45 Episode in   421 steps, reward 9.00\n",
      " 46 Episode in   430 steps, reward 9.00\n",
      " 47 Episode in   440 steps, reward 10.00\n",
      " 48 Episode in   449 steps, reward 9.00\n",
      " 49 Episode in   458 steps, reward 9.00\n",
      " 50 Episode in   469 steps, reward 11.00\n",
      " 51 Episode in   479 steps, reward 10.00\n",
      " 52 Episode in   488 steps, reward 9.00\n",
      " 53 Episode in   497 steps, reward 9.00\n",
      " 54 Episode in   506 steps, reward 9.00\n",
      " 55 Episode in   515 steps, reward 9.00\n",
      " 56 Episode in   524 steps, reward 9.00\n",
      " 57 Episode in   534 steps, reward 10.00\n",
      " 58 Episode in   545 steps, reward 11.00\n",
      " 59 Episode in   553 steps, reward 8.00\n",
      " 60 Episode in   563 steps, reward 10.00\n",
      " 61 Episode in   572 steps, reward 9.00\n",
      " 62 Episode in   581 steps, reward 9.00\n",
      " 63 Episode in   590 steps, reward 9.00\n",
      " 64 Episode in   600 steps, reward 10.00\n",
      " 65 Episode in   609 steps, reward 9.00\n",
      " 66 Episode in   619 steps, reward 10.00\n",
      " 67 Episode in   629 steps, reward 10.00\n",
      " 68 Episode in   639 steps, reward 10.00\n",
      " 69 Episode in   648 steps, reward 9.00\n",
      " 70 Episode in   659 steps, reward 11.00\n",
      " 71 Episode in   670 steps, reward 11.00\n",
      " 72 Episode in   679 steps, reward 9.00\n",
      " 73 Episode in   689 steps, reward 10.00\n",
      " 74 Episode in   698 steps, reward 9.00\n",
      " 75 Episode in   707 steps, reward 9.00\n",
      " 76 Episode in   715 steps, reward 8.00\n",
      " 77 Episode in   724 steps, reward 9.00\n",
      " 78 Episode in   733 steps, reward 9.00\n",
      " 79 Episode in   743 steps, reward 10.00\n",
      " 80 Episode in   754 steps, reward 11.00\n",
      " 81 Episode in   763 steps, reward 9.00\n",
      " 82 Episode in   772 steps, reward 9.00\n",
      " 83 Episode in   781 steps, reward 9.00\n",
      " 84 Episode in   791 steps, reward 10.00\n",
      " 85 Episode in   800 steps, reward 9.00\n",
      " 86 Episode in   808 steps, reward 8.00\n",
      " 87 Episode in   818 steps, reward 10.00\n",
      " 88 Episode in   827 steps, reward 9.00\n",
      " 89 Episode in   836 steps, reward 9.00\n",
      " 90 Episode in   845 steps, reward 9.00\n",
      " 91 Episode in   854 steps, reward 9.00\n",
      " 92 Episode in   863 steps, reward 9.00\n",
      " 93 Episode in   872 steps, reward 9.00\n",
      " 94 Episode in   882 steps, reward 10.00\n",
      " 95 Episode in   892 steps, reward 10.00\n",
      " 96 Episode in   900 steps, reward 8.00\n",
      " 97 Episode in   909 steps, reward 9.00\n",
      " 98 Episode in   919 steps, reward 10.00\n",
      " 99 Episode in   928 steps, reward 9.00\n",
      "100 Episode in   936 steps, reward 8.00\n",
      "101 Episode in   945 steps, reward 9.00\n",
      "102 Episode in   954 steps, reward 9.00\n",
      "103 Episode in   964 steps, reward 10.00\n",
      "104 Episode in   974 steps, reward 10.00\n",
      "105 Episode in   983 steps, reward 9.00\n",
      "106 Episode in   992 steps, reward 9.00\n",
      "107 Episode in  1001 steps, reward 9.00\n",
      "108 Episode in  1010 steps, reward 9.00\n",
      "109 Episode in  1020 steps, reward 10.00\n",
      "110 Episode in  1028 steps, reward 8.00\n",
      "111 Episode in  1038 steps, reward 10.00\n",
      "112 Episode in  1048 steps, reward 10.00\n",
      "113 Episode in  1058 steps, reward 10.00\n",
      "114 Episode in  1068 steps, reward 10.00\n",
      "115 Episode in  1078 steps, reward 10.00\n",
      "116 Episode in  1086 steps, reward 8.00\n",
      "117 Episode in  1096 steps, reward 10.00\n",
      "118 Episode in  1105 steps, reward 9.00\n",
      "119 Episode in  1114 steps, reward 9.00\n",
      "120 Episode in  1123 steps, reward 9.00\n",
      "121 Episode in  1134 steps, reward 11.00\n",
      "122 Episode in  1143 steps, reward 9.00\n",
      "123 Episode in  1152 steps, reward 9.00\n",
      "124 Episode in  1160 steps, reward 8.00\n",
      "125 Episode in  1170 steps, reward 10.00\n",
      "126 Episode in  1178 steps, reward 8.00\n",
      "127 Episode in  1186 steps, reward 8.00\n",
      "128 Episode in  1196 steps, reward 10.00\n",
      "129 Episode in  1206 steps, reward 10.00\n",
      "130 Episode in  1214 steps, reward 8.00\n",
      "131 Episode in  1223 steps, reward 9.00\n",
      "132 Episode in  1232 steps, reward 9.00\n",
      "133 Episode in  1241 steps, reward 9.00\n",
      "134 Episode in  1252 steps, reward 11.00\n",
      "135 Episode in  1262 steps, reward 10.00\n",
      "136 Episode in  1273 steps, reward 11.00\n",
      "137 Episode in  1283 steps, reward 10.00\n",
      "138 Episode in  1293 steps, reward 10.00\n",
      "139 Episode in  1301 steps, reward 8.00\n",
      "140 Episode in  1309 steps, reward 8.00\n",
      "141 Episode in  1317 steps, reward 8.00\n",
      "142 Episode in  1326 steps, reward 9.00\n",
      "143 Episode in  1336 steps, reward 10.00\n",
      "144 Episode in  1347 steps, reward 11.00\n",
      "145 Episode in  1356 steps, reward 9.00\n",
      "146 Episode in  1365 steps, reward 9.00\n",
      "147 Episode in  1374 steps, reward 9.00\n",
      "148 Episode in  1384 steps, reward 10.00\n",
      "149 Episode in  1393 steps, reward 9.00\n",
      "150 Episode in  1404 steps, reward 11.00\n",
      "151 Episode in  1414 steps, reward 10.00\n",
      "152 Episode in  1423 steps, reward 9.00\n",
      "153 Episode in  1432 steps, reward 9.00\n",
      "154 Episode in  1441 steps, reward 9.00\n",
      "155 Episode in  1451 steps, reward 10.00\n",
      "156 Episode in  1460 steps, reward 9.00\n",
      "157 Episode in  1468 steps, reward 8.00\n",
      "158 Episode in  1479 steps, reward 11.00\n",
      "159 Episode in  1489 steps, reward 10.00\n",
      "160 Episode in  1498 steps, reward 9.00\n",
      "\n",
      "============  Start Learning  ============\n",
      "\n",
      "161 Episode in  1508 steps, reward 10.00\n",
      "162 Episode in  1516 steps, reward 8.00\n",
      "163 Episode in  1526 steps, reward 10.00\n",
      "164 Episode in  1535 steps, reward 9.00\n",
      "165 Episode in  1544 steps, reward 9.00\n",
      "166 Episode in  1554 steps, reward 10.00\n",
      "167 Episode in  1564 steps, reward 10.00\n",
      "168 Episode in  1574 steps, reward 10.00\n",
      "169 Episode in  1584 steps, reward 10.00\n",
      "170 Episode in  1593 steps, reward 9.00\n",
      "171 Episode in  1603 steps, reward 10.00\n",
      "172 Episode in  1613 steps, reward 10.00\n",
      "173 Episode in  1621 steps, reward 8.00\n",
      "174 Episode in  1630 steps, reward 9.00\n",
      "175 Episode in  1638 steps, reward 8.00\n",
      "176 Episode in  1648 steps, reward 10.00\n",
      "177 Episode in  1656 steps, reward 8.00\n",
      "178 Episode in  1666 steps, reward 10.00\n",
      "179 Episode in  1676 steps, reward 10.00\n",
      "180 Episode in  1686 steps, reward 10.00\n",
      "181 Episode in  1695 steps, reward 9.00\n",
      "182 Episode in  1704 steps, reward 9.00\n",
      "183 Episode in  1714 steps, reward 10.00\n",
      "184 Episode in  1723 steps, reward 9.00\n",
      "185 Episode in  1732 steps, reward 9.00\n",
      "186 Episode in  1741 steps, reward 9.00\n",
      "187 Episode in  1749 steps, reward 8.00\n",
      "188 Episode in  1759 steps, reward 10.00\n",
      "189 Episode in  1769 steps, reward 10.00\n",
      "190 Episode in  1780 steps, reward 11.00\n",
      "191 Episode in  1788 steps, reward 8.00\n",
      "192 Episode in  1797 steps, reward 9.00\n",
      "193 Episode in  1807 steps, reward 10.00\n",
      "194 Episode in  1817 steps, reward 10.00\n",
      "195 Episode in  1826 steps, reward 9.00\n",
      "196 Episode in  1836 steps, reward 10.00\n",
      "197 Episode in  1844 steps, reward 8.00\n",
      "198 Episode in  1853 steps, reward 9.00\n",
      "199 Episode in  1862 steps, reward 9.00\n",
      "200 Episode in  1872 steps, reward 10.00\n",
      "201 Episode in  1882 steps, reward 10.00\n",
      "202 Episode in  1891 steps, reward 9.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203 Episode in  1899 steps, reward 8.00\n",
      "204 Episode in  1907 steps, reward 8.00\n",
      "205 Episode in  1917 steps, reward 10.00\n",
      "206 Episode in  1926 steps, reward 9.00\n",
      "207 Episode in  1935 steps, reward 9.00\n",
      "208 Episode in  1945 steps, reward 10.00\n",
      "209 Episode in  1953 steps, reward 8.00\n",
      "210 Episode in  1962 steps, reward 9.00\n",
      "211 Episode in  1972 steps, reward 10.00\n",
      "212 Episode in  1980 steps, reward 8.00\n",
      "213 Episode in  1990 steps, reward 10.00\n",
      "214 Episode in  1998 steps, reward 8.00\n",
      "215 Episode in  2007 steps, reward 9.00\n",
      "216 Episode in  2017 steps, reward 10.00\n",
      "217 Episode in  2027 steps, reward 10.00\n",
      "218 Episode in  2035 steps, reward 8.00\n",
      "219 Episode in  2044 steps, reward 9.00\n",
      "220 Episode in  2054 steps, reward 10.00\n",
      "221 Episode in  2062 steps, reward 8.00\n",
      "222 Episode in  2071 steps, reward 9.00\n",
      "223 Episode in  2079 steps, reward 8.00\n",
      "224 Episode in  2089 steps, reward 10.00\n",
      "225 Episode in  2099 steps, reward 10.00\n",
      "226 Episode in  2109 steps, reward 10.00\n",
      "227 Episode in  2119 steps, reward 10.00\n",
      "228 Episode in  2128 steps, reward 9.00\n",
      "229 Episode in  2137 steps, reward 9.00\n",
      "230 Episode in  2145 steps, reward 8.00\n",
      "231 Episode in  2154 steps, reward 9.00\n",
      "232 Episode in  2163 steps, reward 9.00\n",
      "233 Episode in  2172 steps, reward 9.00\n",
      "234 Episode in  2181 steps, reward 9.00\n",
      "235 Episode in  2190 steps, reward 9.00\n",
      "236 Episode in  2202 steps, reward 12.00\n",
      "237 Episode in  2212 steps, reward 10.00\n",
      "238 Episode in  2220 steps, reward 8.00\n",
      "239 Episode in  2234 steps, reward 14.00\n",
      "240 Episode in  2246 steps, reward 12.00\n",
      "241 Episode in  2259 steps, reward 13.00\n",
      "242 Episode in  2279 steps, reward 20.00\n",
      "243 Episode in  2492 steps, reward 213.00\n",
      "244 Episode in  2621 steps, reward 129.00\n",
      "245 Episode in  2664 steps, reward 43.00\n",
      "246 Episode in  2677 steps, reward 13.00\n",
      "247 Episode in  2687 steps, reward 10.00\n",
      "248 Episode in  2696 steps, reward 9.00\n",
      "249 Episode in  2705 steps, reward 9.00\n",
      "250 Episode in  2715 steps, reward 10.00\n",
      "251 Episode in  2724 steps, reward 9.00\n",
      "252 Episode in  2733 steps, reward 9.00\n",
      "253 Episode in  2742 steps, reward 9.00\n",
      "254 Episode in  2752 steps, reward 10.00\n",
      "255 Episode in  2762 steps, reward 10.00\n",
      "256 Episode in  2772 steps, reward 10.00\n",
      "257 Episode in  2781 steps, reward 9.00\n",
      "258 Episode in  2791 steps, reward 10.00\n",
      "259 Episode in  2801 steps, reward 10.00\n",
      "260 Episode in  2812 steps, reward 11.00\n",
      "261 Episode in  2822 steps, reward 10.00\n",
      "262 Episode in  2832 steps, reward 10.00\n",
      "263 Episode in  2841 steps, reward 9.00\n",
      "264 Episode in  2850 steps, reward 9.00\n",
      "265 Episode in  2860 steps, reward 10.00\n",
      "266 Episode in  2870 steps, reward 10.00\n",
      "267 Episode in  2879 steps, reward 9.00\n",
      "268 Episode in  2889 steps, reward 10.00\n",
      "269 Episode in  2900 steps, reward 11.00\n",
      "270 Episode in  2910 steps, reward 10.00\n",
      "271 Episode in  2936 steps, reward 26.00\n",
      "272 Episode in  3006 steps, reward 70.00\n",
      "273 Episode in  3031 steps, reward 25.00\n",
      "274 Episode in  3069 steps, reward 38.00\n",
      "275 Episode in  3119 steps, reward 50.00\n",
      "276 Episode in  3142 steps, reward 23.00\n",
      "277 Episode in  3162 steps, reward 20.00\n",
      "278 Episode in  3182 steps, reward 20.00\n",
      "279 Episode in  3201 steps, reward 19.00\n",
      "280 Episode in  3241 steps, reward 40.00\n",
      "281 Episode in  3282 steps, reward 41.00\n",
      "282 Episode in  3399 steps, reward 117.00\n",
      "283 Episode in  3499 steps, reward 100.00\n",
      "284 Episode in  3596 steps, reward 97.00\n",
      "285 Episode in  3717 steps, reward 121.00\n",
      "286 Episode in  3818 steps, reward 101.00\n",
      "287 Episode in  3918 steps, reward 100.00\n",
      "288 Episode in  4038 steps, reward 120.00\n",
      "289 Episode in  4163 steps, reward 125.00\n",
      "290 Episode in  4280 steps, reward 117.00\n",
      "291 Episode in  4413 steps, reward 133.00\n",
      "292 Episode in  4550 steps, reward 137.00\n",
      "293 Episode in  4710 steps, reward 160.00\n",
      "294 Episode in  4883 steps, reward 173.00\n",
      "295 Episode in  5036 steps, reward 153.00\n",
      "296 Episode in  5197 steps, reward 161.00\n",
      "297 Episode in  5563 steps, reward 366.00\n",
      "298 Episode in  5846 steps, reward 283.00\n",
      "299 Episode in  6029 steps, reward 183.00\n",
      "300 Episode in  6307 steps, reward 278.00\n",
      "301 Episode in  6542 steps, reward 235.00\n",
      "302 Episode in  6736 steps, reward 194.00\n",
      "303 Episode in  6941 steps, reward 205.00\n",
      "304 Episode in  7441 steps, reward 500.00\n",
      "305 Episode in  7941 steps, reward 500.00\n",
      "306 Episode in  8441 steps, reward 500.00\n",
      "307 Episode in  8744 steps, reward 303.00\n",
      "308 Episode in  9179 steps, reward 435.00\n",
      "309 Episode in  9445 steps, reward 266.00\n",
      "310 Episode in  9729 steps, reward 284.00\n",
      "311 Episode in 10145 steps, reward 416.00\n",
      "312 Episode in 10463 steps, reward 318.00\n",
      "313 Episode in 10836 steps, reward 373.00\n",
      "314 Episode in 11154 steps, reward 318.00\n",
      "315 Episode in 11654 steps, reward 500.00\n",
      "316 Episode in 12154 steps, reward 500.00\n",
      "317 Episode in 12654 steps, reward 500.00\n",
      "318 Episode in 13154 steps, reward 500.00\n",
      "319 Episode in 13654 steps, reward 500.00\n",
      "320 Episode in 13956 steps, reward 302.00\n",
      "321 Episode in 14456 steps, reward 500.00\n",
      "322 Episode in 14838 steps, reward 382.00\n",
      "323 Episode in 15338 steps, reward 500.00\n",
      "324 Episode in 15838 steps, reward 500.00\n",
      "325 Episode in 16214 steps, reward 376.00\n",
      "326 Episode in 16509 steps, reward 295.00\n",
      "327 Episode in 17009 steps, reward 500.00\n",
      "328 Episode in 17509 steps, reward 500.00\n",
      "329 Episode in 18009 steps, reward 500.00\n",
      "330 Episode in 18429 steps, reward 420.00\n",
      "331 Episode in 18929 steps, reward 500.00\n",
      "332 Episode in 19429 steps, reward 500.00\n",
      "333 Episode in 19929 steps, reward 500.00\n",
      "334 Episode in 20429 steps, reward 500.00\n",
      "335 Episode in 20810 steps, reward 381.00\n",
      "336 Episode in 21130 steps, reward 320.00\n",
      "337 Episode in 21517 steps, reward 387.00\n",
      "338 Episode in 21881 steps, reward 364.00\n",
      "339 Episode in 22381 steps, reward 500.00\n",
      "340 Episode in 22881 steps, reward 500.00\n",
      "341 Episode in 23284 steps, reward 403.00\n",
      "342 Episode in 23784 steps, reward 500.00\n",
      "343 Episode in 24181 steps, reward 397.00\n",
      "344 Episode in 24615 steps, reward 434.00\n",
      "345 Episode in 25115 steps, reward 500.00\n",
      "346 Episode in 25615 steps, reward 500.00\n",
      "347 Episode in 26115 steps, reward 500.00\n",
      "348 Episode in 26609 steps, reward 494.00\n",
      "349 Episode in 27109 steps, reward 500.00\n",
      "350 Episode in 27392 steps, reward 283.00\n",
      "351 Episode in 27892 steps, reward 500.00\n",
      "352 Episode in 28224 steps, reward 332.00\n",
      "353 Episode in 28527 steps, reward 303.00\n",
      "354 Episode in 28846 steps, reward 319.00\n",
      "355 Episode in 29346 steps, reward 500.00\n",
      "356 Episode in 29846 steps, reward 500.00\n",
      "357 Episode in 30135 steps, reward 289.00\n",
      "358 Episode in 30635 steps, reward 500.00\n",
      "359 Episode in 31135 steps, reward 500.00\n",
      "360 Episode in 31635 steps, reward 500.00\n",
      "361 Episode in 32135 steps, reward 500.00\n",
      "362 Episode in 32630 steps, reward 495.00\n",
      "363 Episode in 33061 steps, reward 431.00\n",
      "364 Episode in 33561 steps, reward 500.00\n",
      "365 Episode in 33876 steps, reward 315.00\n",
      "366 Episode in 34376 steps, reward 500.00\n",
      "367 Episode in 34876 steps, reward 500.00\n",
      "368 Episode in 35376 steps, reward 500.00\n",
      "369 Episode in 35876 steps, reward 500.00\n",
      "370 Episode in 36376 steps, reward 500.00\n",
      "371 Episode in 36736 steps, reward 360.00\n",
      "372 Episode in 37041 steps, reward 305.00\n",
      "373 Episode in 37541 steps, reward 500.00\n",
      "374 Episode in 37806 steps, reward 265.00\n",
      "375 Episode in 38306 steps, reward 500.00\n",
      "376 Episode in 38625 steps, reward 319.00\n",
      "377 Episode in 39125 steps, reward 500.00\n",
      "378 Episode in 39487 steps, reward 362.00\n",
      "379 Episode in 39987 steps, reward 500.00\n",
      "380 Episode in 40487 steps, reward 500.00\n",
      "381 Episode in 40905 steps, reward 418.00\n",
      "382 Episode in 41405 steps, reward 500.00\n",
      "383 Episode in 41905 steps, reward 500.00\n",
      "384 Episode in 42405 steps, reward 500.00\n",
      "385 Episode in 42905 steps, reward 500.00\n",
      "386 Episode in 43248 steps, reward 343.00\n",
      "387 Episode in 43637 steps, reward 389.00\n",
      "388 Episode in 44039 steps, reward 402.00\n",
      "389 Episode in 44537 steps, reward 498.00\n",
      "390 Episode in 44815 steps, reward 278.00\n",
      "391 Episode in 45315 steps, reward 500.00\n",
      "392 Episode in 45815 steps, reward 500.00\n",
      "393 Episode in 46281 steps, reward 466.00\n",
      "394 Episode in 46781 steps, reward 500.00\n",
      "395 Episode in 47113 steps, reward 332.00\n",
      "396 Episode in 47426 steps, reward 313.00\n",
      "397 Episode in 47926 steps, reward 500.00\n",
      "398 Episode in 48426 steps, reward 500.00\n",
      "399 Episode in 48915 steps, reward 489.00\n",
      "400 Episode in 49233 steps, reward 318.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401 Episode in 49733 steps, reward 500.00\n",
      "402 Episode in 50038 steps, reward 305.00\n",
      "403 Episode in 50538 steps, reward 500.00\n",
      "404 Episode in 51038 steps, reward 500.00\n",
      "405 Episode in 51322 steps, reward 284.00\n",
      "406 Episode in 51759 steps, reward 437.00\n",
      "407 Episode in 52259 steps, reward 500.00\n",
      "408 Episode in 52731 steps, reward 472.00\n",
      "409 Episode in 53111 steps, reward 380.00\n",
      "410 Episode in 53512 steps, reward 401.00\n",
      "411 Episode in 53921 steps, reward 409.00\n",
      "412 Episode in 54266 steps, reward 345.00\n",
      "413 Episode in 54549 steps, reward 283.00\n",
      "414 Episode in 55049 steps, reward 500.00\n",
      "415 Episode in 55426 steps, reward 377.00\n",
      "416 Episode in 55684 steps, reward 258.00\n",
      "417 Episode in 56017 steps, reward 333.00\n",
      "418 Episode in 56333 steps, reward 316.00\n",
      "419 Episode in 56833 steps, reward 500.00\n",
      "420 Episode in 57096 steps, reward 263.00\n",
      "421 Episode in 57364 steps, reward 268.00\n",
      "422 Episode in 57664 steps, reward 300.00\n",
      "423 Episode in 58025 steps, reward 361.00\n",
      "424 Episode in 58393 steps, reward 368.00\n",
      "425 Episode in 58658 steps, reward 265.00\n",
      "426 Episode in 58933 steps, reward 275.00\n",
      "427 Episode in 59207 steps, reward 274.00\n",
      "428 Episode in 59452 steps, reward 245.00\n",
      "429 Episode in 59760 steps, reward 308.00\n",
      "430 Episode in 59988 steps, reward 228.00\n",
      "431 Episode in 60218 steps, reward 230.00\n",
      "432 Episode in 60486 steps, reward 268.00\n",
      "433 Episode in 60751 steps, reward 265.00\n",
      "434 Episode in 61176 steps, reward 425.00\n",
      "435 Episode in 61508 steps, reward 332.00\n",
      "436 Episode in 61777 steps, reward 269.00\n",
      "437 Episode in 62067 steps, reward 290.00\n",
      "438 Episode in 62328 steps, reward 261.00\n",
      "439 Episode in 62684 steps, reward 356.00\n",
      "440 Episode in 62966 steps, reward 282.00\n",
      "441 Episode in 63301 steps, reward 335.00\n",
      "442 Episode in 63569 steps, reward 268.00\n",
      "443 Episode in 63880 steps, reward 311.00\n",
      "444 Episode in 64298 steps, reward 418.00\n",
      "445 Episode in 64510 steps, reward 212.00\n",
      "446 Episode in 64762 steps, reward 252.00\n",
      "447 Episode in 64975 steps, reward 213.00\n",
      "448 Episode in 65181 steps, reward 206.00\n",
      "449 Episode in 65390 steps, reward 209.00\n",
      "450 Episode in 65657 steps, reward 267.00\n",
      "451 Episode in 65901 steps, reward 244.00\n",
      "452 Episode in 66187 steps, reward 286.00\n",
      "453 Episode in 66428 steps, reward 241.00\n",
      "454 Episode in 66667 steps, reward 239.00\n",
      "455 Episode in 66887 steps, reward 220.00\n",
      "456 Episode in 67157 steps, reward 270.00\n",
      "457 Episode in 67432 steps, reward 275.00\n",
      "458 Episode in 67714 steps, reward 282.00\n",
      "459 Episode in 67957 steps, reward 243.00\n",
      "460 Episode in 68183 steps, reward 226.00\n",
      "461 Episode in 68411 steps, reward 228.00\n",
      "462 Episode in 68645 steps, reward 234.00\n",
      "463 Episode in 68865 steps, reward 220.00\n",
      "464 Episode in 69067 steps, reward 202.00\n",
      "465 Episode in 69327 steps, reward 260.00\n",
      "466 Episode in 69536 steps, reward 209.00\n",
      "467 Episode in 69760 steps, reward 224.00\n",
      "468 Episode in 69973 steps, reward 213.00\n",
      "469 Episode in 70171 steps, reward 198.00\n",
      "470 Episode in 70356 steps, reward 185.00\n",
      "471 Episode in 70560 steps, reward 204.00\n",
      "472 Episode in 70761 steps, reward 201.00\n",
      "473 Episode in 70958 steps, reward 197.00\n",
      "474 Episode in 71142 steps, reward 184.00\n",
      "475 Episode in 71344 steps, reward 202.00\n",
      "476 Episode in 71529 steps, reward 185.00\n",
      "477 Episode in 71708 steps, reward 179.00\n",
      "478 Episode in 71915 steps, reward 207.00\n",
      "479 Episode in 72106 steps, reward 191.00\n",
      "480 Episode in 72312 steps, reward 206.00\n",
      "481 Episode in 72537 steps, reward 225.00\n",
      "482 Episode in 72783 steps, reward 246.00\n",
      "483 Episode in 72977 steps, reward 194.00\n",
      "484 Episode in 73191 steps, reward 214.00\n",
      "485 Episode in 73429 steps, reward 238.00\n",
      "486 Episode in 73674 steps, reward 245.00\n",
      "487 Episode in 73858 steps, reward 184.00\n",
      "488 Episode in 74027 steps, reward 169.00\n",
      "489 Episode in 74237 steps, reward 210.00\n",
      "490 Episode in 74448 steps, reward 211.00\n",
      "491 Episode in 74633 steps, reward 185.00\n",
      "492 Episode in 74820 steps, reward 187.00\n",
      "493 Episode in 75001 steps, reward 181.00\n",
      "494 Episode in 75173 steps, reward 172.00\n",
      "495 Episode in 75360 steps, reward 187.00\n",
      "496 Episode in 75539 steps, reward 179.00\n",
      "497 Episode in 75704 steps, reward 165.00\n",
      "498 Episode in 75863 steps, reward 159.00\n",
      "499 Episode in 76035 steps, reward 172.00\n",
      "500 Episode in 76232 steps, reward 197.00\n",
      "501 Episode in 76464 steps, reward 232.00\n",
      "502 Episode in 76659 steps, reward 195.00\n",
      "503 Episode in 76892 steps, reward 233.00\n",
      "504 Episode in 77116 steps, reward 224.00\n",
      "505 Episode in 77293 steps, reward 177.00\n",
      "506 Episode in 77453 steps, reward 160.00\n",
      "507 Episode in 77521 steps, reward 68.00\n",
      "508 Episode in 77539 steps, reward 18.00\n",
      "509 Episode in 77552 steps, reward 13.00\n",
      "510 Episode in 77566 steps, reward 14.00\n",
      "511 Episode in 77586 steps, reward 20.00\n",
      "512 Episode in 77614 steps, reward 28.00\n",
      "513 Episode in 77826 steps, reward 212.00\n",
      "514 Episode in 78069 steps, reward 243.00\n",
      "515 Episode in 78569 steps, reward 500.00\n",
      "516 Episode in 79069 steps, reward 500.00\n",
      "517 Episode in 79356 steps, reward 287.00\n",
      "518 Episode in 79756 steps, reward 400.00\n",
      "519 Episode in 80229 steps, reward 473.00\n",
      "520 Episode in 80441 steps, reward 212.00\n",
      "521 Episode in 80696 steps, reward 255.00\n",
      "522 Episode in 81163 steps, reward 467.00\n",
      "523 Episode in 81422 steps, reward 259.00\n",
      "524 Episode in 81658 steps, reward 236.00\n",
      "525 Episode in 81913 steps, reward 255.00\n",
      "526 Episode in 82126 steps, reward 213.00\n",
      "527 Episode in 82421 steps, reward 295.00\n",
      "528 Episode in 82629 steps, reward 208.00\n",
      "529 Episode in 82915 steps, reward 286.00\n",
      "530 Episode in 83148 steps, reward 233.00\n",
      "531 Episode in 83384 steps, reward 236.00\n",
      "532 Episode in 83603 steps, reward 219.00\n",
      "533 Episode in 83780 steps, reward 177.00\n",
      "534 Episode in 84018 steps, reward 238.00\n",
      "535 Episode in 84237 steps, reward 219.00\n",
      "536 Episode in 84485 steps, reward 248.00\n",
      "537 Episode in 84682 steps, reward 197.00\n",
      "538 Episode in 84868 steps, reward 186.00\n",
      "539 Episode in 85085 steps, reward 217.00\n",
      "540 Episode in 85312 steps, reward 227.00\n",
      "541 Episode in 85517 steps, reward 205.00\n",
      "542 Episode in 85723 steps, reward 206.00\n",
      "543 Episode in 85985 steps, reward 262.00\n",
      "544 Episode in 86220 steps, reward 235.00\n",
      "545 Episode in 86424 steps, reward 204.00\n",
      "546 Episode in 86614 steps, reward 190.00\n",
      "547 Episode in 86799 steps, reward 185.00\n",
      "548 Episode in 86972 steps, reward 173.00\n",
      "549 Episode in 87181 steps, reward 209.00\n",
      "550 Episode in 87370 steps, reward 189.00\n",
      "551 Episode in 87574 steps, reward 204.00\n",
      "552 Episode in 87810 steps, reward 236.00\n",
      "553 Episode in 87973 steps, reward 163.00\n",
      "554 Episode in 88093 steps, reward 120.00\n",
      "555 Episode in 88248 steps, reward 155.00\n",
      "556 Episode in 88427 steps, reward 179.00\n",
      "557 Episode in 88659 steps, reward 232.00\n",
      "558 Episode in 88831 steps, reward 172.00\n",
      "559 Episode in 89085 steps, reward 254.00\n",
      "560 Episode in 89283 steps, reward 198.00\n",
      "561 Episode in 89442 steps, reward 159.00\n",
      "562 Episode in 89637 steps, reward 195.00\n",
      "563 Episode in 89853 steps, reward 216.00\n",
      "564 Episode in 90076 steps, reward 223.00\n",
      "565 Episode in 90316 steps, reward 240.00\n",
      "566 Episode in 90497 steps, reward 181.00\n",
      "567 Episode in 90675 steps, reward 178.00\n",
      "568 Episode in 90923 steps, reward 248.00\n",
      "569 Episode in 91094 steps, reward 171.00\n",
      "570 Episode in 91277 steps, reward 183.00\n",
      "571 Episode in 91467 steps, reward 190.00\n",
      "572 Episode in 91664 steps, reward 197.00\n",
      "573 Episode in 91844 steps, reward 180.00\n",
      "574 Episode in 92276 steps, reward 432.00\n",
      "575 Episode in 92561 steps, reward 285.00\n",
      "576 Episode in 92915 steps, reward 354.00\n",
      "577 Episode in 93209 steps, reward 294.00\n",
      "578 Episode in 93434 steps, reward 225.00\n",
      "579 Episode in 93651 steps, reward 217.00\n",
      "580 Episode in 93882 steps, reward 231.00\n",
      "581 Episode in 94249 steps, reward 367.00\n",
      "582 Episode in 94542 steps, reward 293.00\n",
      "583 Episode in 94882 steps, reward 340.00\n",
      "584 Episode in 95250 steps, reward 368.00\n",
      "585 Episode in 95437 steps, reward 187.00\n",
      "586 Episode in 95607 steps, reward 170.00\n",
      "587 Episode in 95787 steps, reward 180.00\n",
      "588 Episode in 96002 steps, reward 215.00\n",
      "589 Episode in 96250 steps, reward 248.00\n",
      "590 Episode in 96411 steps, reward 161.00\n",
      "591 Episode in 96630 steps, reward 219.00\n",
      "592 Episode in 96805 steps, reward 175.00\n",
      "593 Episode in 96975 steps, reward 170.00\n",
      "594 Episode in 97175 steps, reward 200.00\n",
      "595 Episode in 97365 steps, reward 190.00\n",
      "596 Episode in 97552 steps, reward 187.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "597 Episode in 97763 steps, reward 211.00\n",
      "598 Episode in 97944 steps, reward 181.00\n",
      "599 Episode in 98131 steps, reward 187.00\n",
      "600 Episode in 98321 steps, reward 190.00\n",
      "601 Episode in 98491 steps, reward 170.00\n",
      "602 Episode in 98811 steps, reward 320.00\n",
      "603 Episode in 98970 steps, reward 159.00\n",
      "604 Episode in 99193 steps, reward 223.00\n",
      "605 Episode in 99363 steps, reward 170.00\n",
      "606 Episode in 99540 steps, reward 177.00\n",
      "607 Episode in 99693 steps, reward 153.00\n",
      "608 Episode in 99876 steps, reward 183.00\n",
      "609 Episode in 100070 steps, reward 194.00\n",
      "610 Episode in 100228 steps, reward 158.00\n",
      "611 Episode in 100433 steps, reward 205.00\n",
      "612 Episode in 100601 steps, reward 168.00\n",
      "613 Episode in 100805 steps, reward 204.00\n",
      "614 Episode in 100982 steps, reward 177.00\n",
      "615 Episode in 101173 steps, reward 191.00\n",
      "616 Episode in 101359 steps, reward 186.00\n",
      "617 Episode in 101545 steps, reward 186.00\n",
      "618 Episode in 101738 steps, reward 193.00\n",
      "619 Episode in 101991 steps, reward 253.00\n",
      "620 Episode in 102219 steps, reward 228.00\n",
      "621 Episode in 102427 steps, reward 208.00\n",
      "622 Episode in 102579 steps, reward 152.00\n",
      "623 Episode in 102838 steps, reward 259.00\n",
      "624 Episode in 103146 steps, reward 308.00\n",
      "625 Episode in 103289 steps, reward 143.00\n",
      "626 Episode in 103448 steps, reward 159.00\n",
      "627 Episode in 103646 steps, reward 198.00\n",
      "628 Episode in 103854 steps, reward 208.00\n",
      "629 Episode in 104036 steps, reward 182.00\n",
      "630 Episode in 104224 steps, reward 188.00\n",
      "631 Episode in 104445 steps, reward 221.00\n",
      "632 Episode in 104617 steps, reward 172.00\n",
      "633 Episode in 104822 steps, reward 205.00\n",
      "634 Episode in 105118 steps, reward 296.00\n",
      "635 Episode in 105520 steps, reward 402.00\n",
      "636 Episode in 105725 steps, reward 205.00\n",
      "637 Episode in 106119 steps, reward 394.00\n",
      "638 Episode in 106300 steps, reward 181.00\n",
      "639 Episode in 106579 steps, reward 279.00\n",
      "640 Episode in 106813 steps, reward 234.00\n",
      "641 Episode in 106968 steps, reward 155.00\n",
      "642 Episode in 107156 steps, reward 188.00\n",
      "643 Episode in 107346 steps, reward 190.00\n",
      "644 Episode in 107531 steps, reward 185.00\n",
      "645 Episode in 107704 steps, reward 173.00\n",
      "646 Episode in 107953 steps, reward 249.00\n",
      "647 Episode in 108138 steps, reward 185.00\n",
      "648 Episode in 108367 steps, reward 229.00\n",
      "649 Episode in 108582 steps, reward 215.00\n",
      "650 Episode in 109082 steps, reward 500.00\n",
      "651 Episode in 109337 steps, reward 255.00\n",
      "652 Episode in 109568 steps, reward 231.00\n",
      "653 Episode in 109793 steps, reward 225.00\n",
      "654 Episode in 110052 steps, reward 259.00\n",
      "655 Episode in 110405 steps, reward 353.00\n",
      "656 Episode in 110659 steps, reward 254.00\n",
      "657 Episode in 110988 steps, reward 329.00\n",
      "658 Episode in 111488 steps, reward 500.00\n",
      "659 Episode in 111700 steps, reward 212.00\n",
      "660 Episode in 111939 steps, reward 239.00\n",
      "661 Episode in 112366 steps, reward 427.00\n",
      "662 Episode in 112580 steps, reward 214.00\n",
      "663 Episode in 113080 steps, reward 500.00\n",
      "664 Episode in 113266 steps, reward 186.00\n",
      "665 Episode in 113453 steps, reward 187.00\n",
      "666 Episode in 113705 steps, reward 252.00\n",
      "667 Episode in 113945 steps, reward 240.00\n",
      "668 Episode in 114103 steps, reward 158.00\n",
      "669 Episode in 114453 steps, reward 350.00\n",
      "670 Episode in 114755 steps, reward 302.00\n",
      "671 Episode in 114983 steps, reward 228.00\n",
      "672 Episode in 115307 steps, reward 324.00\n",
      "673 Episode in 115554 steps, reward 247.00\n",
      "674 Episode in 115912 steps, reward 358.00\n",
      "675 Episode in 116211 steps, reward 299.00\n",
      "676 Episode in 116491 steps, reward 280.00\n",
      "677 Episode in 116754 steps, reward 263.00\n",
      "678 Episode in 116985 steps, reward 231.00\n",
      "679 Episode in 117271 steps, reward 286.00\n",
      "680 Episode in 117527 steps, reward 256.00\n",
      "681 Episode in 117817 steps, reward 290.00\n",
      "682 Episode in 118129 steps, reward 312.00\n",
      "683 Episode in 118457 steps, reward 328.00\n",
      "684 Episode in 118679 steps, reward 222.00\n",
      "685 Episode in 118929 steps, reward 250.00\n",
      "686 Episode in 119145 steps, reward 216.00\n",
      "687 Episode in 119555 steps, reward 410.00\n",
      "688 Episode in 119779 steps, reward 224.00\n",
      "689 Episode in 119998 steps, reward 219.00\n",
      "690 Episode in 120303 steps, reward 305.00\n",
      "691 Episode in 120579 steps, reward 276.00\n",
      "692 Episode in 120856 steps, reward 277.00\n",
      "693 Episode in 121068 steps, reward 212.00\n",
      "694 Episode in 121259 steps, reward 191.00\n",
      "695 Episode in 121455 steps, reward 196.00\n",
      "696 Episode in 121733 steps, reward 278.00\n",
      "697 Episode in 121961 steps, reward 228.00\n",
      "698 Episode in 122178 steps, reward 217.00\n",
      "699 Episode in 122434 steps, reward 256.00\n",
      "700 Episode in 122626 steps, reward 192.00\n",
      "701 Episode in 122876 steps, reward 250.00\n",
      "702 Episode in 123052 steps, reward 176.00\n",
      "703 Episode in 123236 steps, reward 184.00\n",
      "704 Episode in 123418 steps, reward 182.00\n",
      "705 Episode in 123649 steps, reward 231.00\n",
      "706 Episode in 123851 steps, reward 202.00\n",
      "707 Episode in 124130 steps, reward 279.00\n",
      "708 Episode in 124314 steps, reward 184.00\n",
      "709 Episode in 124564 steps, reward 250.00\n",
      "710 Episode in 124808 steps, reward 244.00\n",
      "711 Episode in 125027 steps, reward 219.00\n",
      "712 Episode in 125403 steps, reward 376.00\n",
      "713 Episode in 125619 steps, reward 216.00\n",
      "714 Episode in 125840 steps, reward 221.00\n",
      "715 Episode in 126165 steps, reward 325.00\n",
      "716 Episode in 126403 steps, reward 238.00\n",
      "717 Episode in 126592 steps, reward 189.00\n",
      "718 Episode in 126823 steps, reward 231.00\n",
      "719 Episode in 127087 steps, reward 264.00\n",
      "720 Episode in 127340 steps, reward 253.00\n",
      "721 Episode in 127782 steps, reward 442.00\n",
      "722 Episode in 128022 steps, reward 240.00\n",
      "723 Episode in 128284 steps, reward 262.00\n",
      "724 Episode in 128742 steps, reward 458.00\n",
      "725 Episode in 129023 steps, reward 281.00\n",
      "726 Episode in 129309 steps, reward 286.00\n",
      "727 Episode in 129801 steps, reward 492.00\n",
      "728 Episode in 129990 steps, reward 189.00\n",
      "729 Episode in 130152 steps, reward 162.00\n",
      "730 Episode in 130326 steps, reward 174.00\n",
      "731 Episode in 130624 steps, reward 298.00\n",
      "732 Episode in 130861 steps, reward 237.00\n",
      "733 Episode in 131141 steps, reward 280.00\n",
      "734 Episode in 131525 steps, reward 384.00\n",
      "735 Episode in 131746 steps, reward 221.00\n",
      "736 Episode in 132009 steps, reward 263.00\n",
      "737 Episode in 132268 steps, reward 259.00\n",
      "738 Episode in 132768 steps, reward 500.00\n",
      "739 Episode in 133119 steps, reward 351.00\n",
      "740 Episode in 133468 steps, reward 349.00\n",
      "741 Episode in 133956 steps, reward 488.00\n",
      "742 Episode in 134389 steps, reward 433.00\n",
      "743 Episode in 134587 steps, reward 198.00\n",
      "744 Episode in 134682 steps, reward 95.00\n",
      "745 Episode in 135052 steps, reward 370.00\n",
      "746 Episode in 135273 steps, reward 221.00\n",
      "747 Episode in 135485 steps, reward 212.00\n",
      "748 Episode in 135759 steps, reward 274.00\n",
      "749 Episode in 135923 steps, reward 164.00\n",
      "750 Episode in 136301 steps, reward 378.00\n",
      "751 Episode in 136520 steps, reward 219.00\n",
      "752 Episode in 136713 steps, reward 193.00\n",
      "753 Episode in 136853 steps, reward 140.00\n",
      "754 Episode in 137024 steps, reward 171.00\n",
      "755 Episode in 137265 steps, reward 241.00\n",
      "756 Episode in 137591 steps, reward 326.00\n",
      "757 Episode in 137819 steps, reward 228.00\n",
      "758 Episode in 137969 steps, reward 150.00\n",
      "759 Episode in 138151 steps, reward 182.00\n",
      "760 Episode in 138396 steps, reward 245.00\n",
      "761 Episode in 138702 steps, reward 306.00\n",
      "762 Episode in 138917 steps, reward 215.00\n",
      "763 Episode in 139095 steps, reward 178.00\n",
      "764 Episode in 139449 steps, reward 354.00\n",
      "765 Episode in 139650 steps, reward 201.00\n",
      "766 Episode in 139899 steps, reward 249.00\n",
      "767 Episode in 140168 steps, reward 269.00\n",
      "768 Episode in 140378 steps, reward 210.00\n",
      "769 Episode in 140538 steps, reward 160.00\n",
      "770 Episode in 140695 steps, reward 157.00\n",
      "771 Episode in 140996 steps, reward 301.00\n",
      "772 Episode in 141266 steps, reward 270.00\n",
      "773 Episode in 141498 steps, reward 232.00\n",
      "774 Episode in 141781 steps, reward 283.00\n",
      "775 Episode in 142039 steps, reward 258.00\n",
      "776 Episode in 142280 steps, reward 241.00\n",
      "777 Episode in 142516 steps, reward 236.00\n",
      "778 Episode in 142985 steps, reward 469.00\n",
      "779 Episode in 143079 steps, reward 94.00\n",
      "780 Episode in 143335 steps, reward 256.00\n",
      "781 Episode in 143613 steps, reward 278.00\n",
      "782 Episode in 143928 steps, reward 315.00\n",
      "783 Episode in 144129 steps, reward 201.00\n",
      "784 Episode in 144390 steps, reward 261.00\n",
      "785 Episode in 144676 steps, reward 286.00\n",
      "786 Episode in 144872 steps, reward 196.00\n",
      "787 Episode in 145105 steps, reward 233.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "788 Episode in 145273 steps, reward 168.00\n",
      "789 Episode in 145560 steps, reward 287.00\n",
      "790 Episode in 145817 steps, reward 257.00\n",
      "791 Episode in 146031 steps, reward 214.00\n",
      "792 Episode in 146214 steps, reward 183.00\n",
      "793 Episode in 146464 steps, reward 250.00\n",
      "794 Episode in 146698 steps, reward 234.00\n",
      "795 Episode in 146952 steps, reward 254.00\n",
      "796 Episode in 147196 steps, reward 244.00\n",
      "797 Episode in 147407 steps, reward 211.00\n",
      "798 Episode in 147604 steps, reward 197.00\n",
      "799 Episode in 147816 steps, reward 212.00\n",
      "800 Episode in 148012 steps, reward 196.00\n",
      "801 Episode in 148121 steps, reward 109.00\n",
      "802 Episode in 148340 steps, reward 219.00\n",
      "803 Episode in 148527 steps, reward 187.00\n",
      "804 Episode in 148694 steps, reward 167.00\n",
      "805 Episode in 148902 steps, reward 208.00\n",
      "806 Episode in 149067 steps, reward 165.00\n",
      "807 Episode in 149210 steps, reward 143.00\n",
      "808 Episode in 149364 steps, reward 154.00\n",
      "809 Episode in 149582 steps, reward 218.00\n",
      "810 Episode in 149921 steps, reward 339.00\n",
      "811 Episode in 150227 steps, reward 306.00\n",
      "812 Episode in 150424 steps, reward 197.00\n",
      "813 Episode in 150687 steps, reward 263.00\n",
      "814 Episode in 150882 steps, reward 195.00\n",
      "815 Episode in 151292 steps, reward 410.00\n",
      "816 Episode in 151524 steps, reward 232.00\n",
      "817 Episode in 151841 steps, reward 317.00\n",
      "818 Episode in 152279 steps, reward 438.00\n",
      "819 Episode in 152655 steps, reward 376.00\n",
      "820 Episode in 152789 steps, reward 134.00\n",
      "821 Episode in 153037 steps, reward 248.00\n",
      "822 Episode in 153284 steps, reward 247.00\n",
      "823 Episode in 153578 steps, reward 294.00\n",
      "824 Episode in 153840 steps, reward 262.00\n",
      "825 Episode in 154060 steps, reward 220.00\n",
      "826 Episode in 154205 steps, reward 145.00\n",
      "827 Episode in 154409 steps, reward 204.00\n",
      "828 Episode in 154528 steps, reward 119.00\n",
      "829 Episode in 154666 steps, reward 138.00\n",
      "830 Episode in 154794 steps, reward 128.00\n",
      "831 Episode in 154908 steps, reward 114.00\n",
      "832 Episode in 155173 steps, reward 265.00\n",
      "833 Episode in 155322 steps, reward 149.00\n",
      "834 Episode in 155436 steps, reward 114.00\n",
      "835 Episode in 155554 steps, reward 118.00\n",
      "836 Episode in 155822 steps, reward 268.00\n",
      "837 Episode in 156060 steps, reward 238.00\n",
      "838 Episode in 156239 steps, reward 179.00\n",
      "839 Episode in 156353 steps, reward 114.00\n",
      "840 Episode in 156480 steps, reward 127.00\n",
      "841 Episode in 156590 steps, reward 110.00\n",
      "842 Episode in 156739 steps, reward 149.00\n",
      "843 Episode in 156948 steps, reward 209.00\n",
      "844 Episode in 157203 steps, reward 255.00\n",
      "845 Episode in 157342 steps, reward 139.00\n",
      "846 Episode in 157620 steps, reward 278.00\n",
      "847 Episode in 158109 steps, reward 489.00\n",
      "848 Episode in 158238 steps, reward 129.00\n",
      "849 Episode in 158474 steps, reward 236.00\n",
      "850 Episode in 158590 steps, reward 116.00\n",
      "851 Episode in 158839 steps, reward 249.00\n",
      "852 Episode in 158949 steps, reward 110.00\n",
      "853 Episode in 159067 steps, reward 118.00\n"
     ]
    }
   ],
   "source": [
    "# play\n",
    "for i in range(1, n_episodes + 1):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    ep_reward = 0\n",
    "    while not done:\n",
    "#         env.render()\n",
    "        if np.random.rand() < epsilon:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            action = select_action(obs, target_net)\n",
    "\n",
    "        _obs, reward, done, _ = env.step(action)\n",
    "\n",
    "        rep_memory.append((obs, action, reward, _obs, done))\n",
    "\n",
    "        obs = _obs\n",
    "        total_steps += 1\n",
    "        ep_reward += reward\n",
    "\n",
    "        if use_eps_decay:\n",
    "            epsilon -= epsilon * decay_rate\n",
    "            epsilon = max(eps_min, epsilon)\n",
    "\n",
    "        if len(rep_memory) >= learn_start:\n",
    "            if len(rep_memory) == learn_start:\n",
    "                print('\\n============  Start Learning  ============\\n')\n",
    "            learn(net, target_net, optimizer, rep_memory)\n",
    "            learn_steps += 1\n",
    "\n",
    "        if learn_steps == update_frq:\n",
    "            # target smoothing update\n",
    "            for t, n in zip(target_net.parameters(), net.parameters()):\n",
    "                t.data = UP_COEF * n.data + (1 - UP_COEF) * t.data\n",
    "            learn_steps = 0\n",
    "\n",
    "    if done:\n",
    "        rewards.append(ep_reward)\n",
    "        reward_eval.append(ep_reward)\n",
    "        print('{:3} Episode in {:5} steps, reward {:.2f}'.format(\n",
    "            i, total_steps, ep_reward))\n",
    "\n",
    "        if len(reward_eval) >= n_eval:\n",
    "            if np.mean(reward_eval) >= env.spec.reward_threshold:\n",
    "                print('\\n{} is sloved! {:3} Episode in {:3} steps'.format(\n",
    "                    env.spec.id, i, total_steps))\n",
    "                torch.save(target_net.state_dict(),\n",
    "                           f'./test/saved_models/{env.spec.id}_ep{i}_clear_model_cdddqn.pt')\n",
    "                break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.title('Reward')\n",
    "plt.plot(rewards)\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.title('Loss')\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    ('CartPole-v0', 385, 0.05),\n",
    "    ('CartPole-v1', None, 0.05),\n",
    "    ('MountainCar-v0', None, 0.1),\n",
    "    ('LunarLander-v2', None, 0.1)\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "C51_tensorflow.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
